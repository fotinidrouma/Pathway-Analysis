{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d7066f",
   "metadata": {},
   "source": [
    "# Must compute for each sample the score with each tool's methodology\n",
    "- Create a 3d DataFrame, where rows are sub-paths, columns are samples (ERpos or ERneg) and cells are in list form the subpaths with the values of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5935fe6",
   "metadata": {},
   "source": [
    "# 1. Read data and make them easier to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d7c82",
   "metadata": {},
   "source": [
    "## 1.1. GSE2034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gse2034_df = pd.read_csv('Data/GSE2034.zip', compression='zip', header=0, sep='\\t', quotechar='\"') # Breast cancer\n",
    "gse2034_df=raw_gse2034_df.copy()\n",
    "\n",
    "# preprocess dataset\n",
    "gse2034_df[['Gene','KEGG-ID']] = gse2034_df['Class'].str.split('#',expand=True)\n",
    "gse2034_df.drop('Class', inplace=True, axis=1)\n",
    "cols = gse2034_df.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "gse2034_df=gse2034_df[cols]\n",
    "\n",
    "#gse2034_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names (estrogen receptor)\n",
    "labels=gse2034_df.columns[2:]\n",
    "for x in range(len(labels)):\n",
    "    if(labels[x].startswith('ERpos')):\n",
    "        labels.values[x]=\"ERpos\"\n",
    "    elif(labels[x].startswith('ERneg')):\n",
    "        labels.values[x]=\"ERneg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4764752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the genes that are present in the GSE2034 dataset and create a dictionary \n",
    "# where the keys are the genes and the values are the corresponding KEGG-IDs\n",
    "# 'a gene can be mapped to more than one Entrez identifier'\n",
    "gene_list=sorted(set(gse2034_df['Gene'].tolist()))\n",
    "gene_dict={}\n",
    "for i in gene_list:\n",
    "    tmp=(gse2034_df.loc[gse2034_df['Gene'] == i]['KEGG-ID']).copy()\n",
    "    tmp_list=[]\n",
    "    for t in tmp:\n",
    "        tmp_list.append(t)\n",
    "    gene_dict.update({i:tmp_list})\n",
    "#print('Gene dictionary (key: Genes, values: KEGG-IDs): '+str(gene_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a13d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose dataframe so that the columns indicate the genes\n",
    "# and rows correspond to samples (class: ERpos or ERneg)\n",
    "genes=(gse2034_df['Gene']).copy()\n",
    "gse2034_df.drop('KEGG-ID', inplace=True, axis=1)\n",
    "gse2034_df=np.transpose(gse2034_df.iloc[:,1:])\n",
    "gse2034_df.columns=genes.values.tolist()\n",
    "#gse2034_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24785ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because one gene might correspond to more than one KEGG-IDs, we calculate the average (or max)\n",
    "# value and get the following simplified dataframe\n",
    "gse2034_df=gse2034_df.groupby(level=0,axis=1).mean()\n",
    "gse2034_df['noProbe']=gse2034_df.mean(axis=1) # Compute 'noProbe' for future use\n",
    "gse2034_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47c249",
   "metadata": {},
   "source": [
    "## 1.2. Selected\n",
    "Cellular processes (15), Signal transduction (Environmental information process) (24), Cancer overview (8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d030d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_selected_df = pd.read_csv('Data/Selected.zip', compression='zip', header=0, sep='\\t', quotechar='\"')[['SubPathID']]\n",
    "#raw_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of nodes relations\n",
    "relations_dict={'Activation':'-->','Inhibition':'--|'}\n",
    "#relations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025936d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Split each pathway based on the relation\n",
    "def split_path(data,relation):\n",
    "    s=[]\n",
    "    cnt=len(data.split(relations_dict[relation]))\n",
    "    cnt_tmp=1\n",
    "    # If there is at least one relation, then split data\n",
    "    if(cnt>0):\n",
    "        for e in data.split(relations_dict[relation]):\n",
    "            if e:\n",
    "                s.append(e)\n",
    "                # Remove the final relation\n",
    "                if(cnt_tmp<cnt):\n",
    "                    s.append(relations_dict[relation])\n",
    "                cnt_tmp+=1\n",
    "    return s\n",
    "\n",
    "# Make the selected dataset easier to understand, by splitting each pathway based on their nodes and edges\n",
    "def get_pathway(data):\n",
    "    s=split_path(data,'Activation')\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        tmp_s=split_path(s[i],'Inhibition')\n",
    "        if(len(s[i])>1):\n",
    "            s[i]=tmp_s\n",
    "            \n",
    "    return list(chain.from_iterable(s))\n",
    "\n",
    "subpaths_list=[get_pathway(row) for row in raw_selected_df['SubPathID']]\n",
    "#subpaths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df=pd.DataFrame(subpaths_list).fillna(value=np.nan) # Rows: pathways, Cols: edges and nodes\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7e76f",
   "metadata": {},
   "source": [
    "## 1.3. Important values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa9dbb",
   "metadata": {},
   "source": [
    "### 1.3.1. Node genes- all genes of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f59407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each node in a pathway represents a discrete function mapping to one or more transcript.\n",
    "# Returns a dictionary corresponding each node of each pathway to its gene or genes.\n",
    "def Node_genes(df):\n",
    "    Node_genes={}\n",
    "    for path in range(df.shape[0]):\n",
    "        tmp_node=[]\n",
    "        for node in range(0,len(df.iloc[path][~df.iloc[path].isnull()]),2):\n",
    "            genes=list(filter(None,[x.strip() for x in df.iloc[path,node].split(' ')]))\n",
    "            tmp_genes=[]\n",
    "            for g in genes:\n",
    "                tmp_genes.append(list(filter(None,[x.strip() for x in g.split('#')]))[0])\n",
    "            tmp_node.append(tmp_genes)\n",
    "        Node_genes.update({path:tmp_node})\n",
    "    return Node_genes\n",
    "\n",
    "node_genes=Node_genes(selected_df)\n",
    "node_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cfedb1",
   "metadata": {},
   "source": [
    "### 1.3.2. Expression value\n",
    "For each subpath assign each sample's genes expression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Calculate each gene's expression value\n",
    "def expression_value(df):\n",
    "    expr_val_dict={}\n",
    "    \n",
    "    for gene in df.columns:\n",
    "        # Get average value for each case\n",
    "        expr_val=df[gene].mean()\n",
    "        \n",
    "        expr_val_dict.update({gene:expr_val})\n",
    "        \n",
    "    return expr_val_dict        \n",
    "\n",
    "expr_val=expression_value(gse2034_df)\n",
    "genes_df=pd.DataFrame(expr_val.values(),index=expr_val.keys(),columns=['Expression Value'])\n",
    "genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each node of a sub-path consisting of more than one genes, get the average value of the expression values.\n",
    "def path_expression_value(path_no):\n",
    "    cur_path=[]\n",
    "    for node in node_genes[path_no]:\n",
    "        cur_node=[]\n",
    "        for gene in node:\n",
    "            # Check if gene is not in genes' list and assign to it the 'noProbe' value\n",
    "            if(not(gene in gene_dict.keys())):\n",
    "                cur_node.append(genes_df.loc['noProbe']['Expression Value'])\n",
    "                continue\n",
    "            cur_node.append(genes_df.loc[gene]['Expression Value'])\n",
    "        cur_path.append(mean(cur_node))\n",
    "    return cur_path\n",
    "         \n",
    "def get_expression_values(node_genes):\n",
    "    expression_values={}\n",
    "    for path in node_genes:\n",
    "        expression_values.update({path:path_expression_value(path)})  \n",
    "    return expression_values\n",
    "\n",
    "expression_values_dict=get_expression_values(node_genes)\n",
    "expression_values_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e525c3",
   "metadata": {},
   "source": [
    "### 1.3.3. P-value and threshold <= 0.05 (gene is significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59182152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt, abs, round\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calculates the p-value of each gene\n",
    "def twoSampZ(X1, X2, mudiff, sd1, sd2, n1, n2):\n",
    "    pooledSE = sqrt(sd1**2/n1 + sd2**2/n2)\n",
    "    z = ((X1 - X2) - mudiff)/pooledSE\n",
    "    pval = 2*(1 - norm.cdf(abs(z)))\n",
    "    return round(z,3), pval\n",
    "\n",
    "def get_genes_pvalue(df):\n",
    "    pos_mean=df['ERpos'].mean(axis=1)\n",
    "    neg_mean=df['ERneg'].mean(axis=1)\n",
    "    pos_std=df['ERpos'].std(axis=1)\n",
    "    neg_std=df['ERneg'].std(axis=1)\n",
    "    no_of_pos=df['ERpos'].count(axis=1)\n",
    "    no_of_neg=df['ERneg'].count(axis=1)\n",
    "\n",
    "    z,p = twoSampZ(pos_mean,neg_mean,0,pos_std,neg_std,no_of_pos,no_of_neg)\n",
    "    return z,p\n",
    "    \n",
    "z,pvalue = get_genes_pvalue(gse2034_df.T)\n",
    "#genes_df=pd.DataFrame(pvalue,columns=['P-value'],index=gse2034_df.columns)\n",
    "genes_df['P-value']=pvalue\n",
    "genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25670e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each node of a sub-path consisting of more than one genes, get the average value of the p-values.\n",
    "def path_pvalue(path,df):\n",
    "    cur_path=np.array([])\n",
    "    for node in path:\n",
    "        cur_node=np.array([])\n",
    "        for gene in node:\n",
    "            # Check if gene is not in genes' list\n",
    "            if(not(gene in df.index)):\n",
    "                cur_node=np.append(cur_node,df.loc['noProbe']['P-value'])\n",
    "                continue\n",
    "            cur_node=np.append(cur_node,df.loc[gene]['P-value'])\n",
    "        cur_path=np.append(cur_path,np.mean(cur_node))\n",
    "    return cur_path\n",
    "         \n",
    "def get_pvalues(node_genes,df):\n",
    "    pvalues={}\n",
    "    for path in node_genes:\n",
    "        pvalues.update({path:path_pvalue(node_genes[path],df)})  \n",
    "    return pvalues\n",
    "\n",
    "pvalue_threshold=0.05\n",
    "pvalues_dict=get_pvalues(node_genes,genes_df)\n",
    "pvalues_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac746e3",
   "metadata": {},
   "source": [
    "### 1.3.4. Fold Change and Log Fold Change\n",
    "Add fold change column to genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319230af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fold change for each gene\n",
    "def fold_change(df):\n",
    "    fc_dict={}\n",
    "    \n",
    "    for gene in df.columns:\n",
    "        # Get average value for each case\n",
    "        erneg_av=df[gene]['ERneg'].mean()\n",
    "        erpos_av=df[gene]['ERpos'].mean()\n",
    "        \n",
    "        # Calculate fold change (B/A)\n",
    "        cur_fc=erneg_av/erpos_av\n",
    "        fc_dict.update({gene:cur_fc})\n",
    "        \n",
    "    #fc_dict.update({'noProbe':mean(list(fc_dict.values()))})\n",
    "        \n",
    "    return fc_dict        \n",
    "\n",
    "fc=fold_change(gse2034_df)\n",
    "genes_df['Fold Change']=fc.values()\n",
    "genes_df['Log FC']=[math.log(fc+1-min(genes_df['Fold Change'])) for fc in genes_df['Fold Change']] # Calculate log fold change\n",
    "genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each node of a sub-path consisting of more than one genes, get the average value of the fold change.\n",
    "def path_fc(path,df):\n",
    "    fc=np.array([])\n",
    "    log_fc=np.array([])\n",
    "    for node in path:\n",
    "        cur_fc=np.array([])\n",
    "        cur_log_fc=np.array([])\n",
    "        for gene in node:\n",
    "            # Check if gene is not in genes' list\n",
    "            if(not(gene in df.index)):\n",
    "                cur_fc=np.append(cur_fc,df.loc['noProbe']['Fold Change'])\n",
    "                cur_log_fc=np.append(cur_log_fc,df.loc['noProbe']['Log FC'])\n",
    "                continue\n",
    "            cur_fc=np.append(cur_fc,df.loc[gene]['Fold Change'])\n",
    "            cur_log_fc=np.append(cur_log_fc,df.loc[gene]['Log FC'])\n",
    "        fc=np.append(fc,np.mean(cur_fc))\n",
    "        log_fc=np.append(log_fc,np.mean(cur_log_fc))\n",
    "    return fc,log_fc\n",
    "            \n",
    "\n",
    "def get_fc(node_genes,df):\n",
    "    fc={}\n",
    "    log_fc={}\n",
    "    for path in node_genes:\n",
    "        cur_fc,cur_log_fc=path_fc(node_genes[path],df)\n",
    "        fc.update({path:cur_fc})  \n",
    "        log_fc.update({path:cur_log_fc})  \n",
    "    return fc,log_fc\n",
    "\n",
    "log_fc_threshold=1.5 \n",
    "fc_dict,log_fc_dict=get_fc(node_genes,genes_df) # Return fold change and log fold change in dictionary form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aa191",
   "metadata": {},
   "source": [
    "### 1.3.5. Differentially Expressed Genes (DEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_df['DEG']=[1 if p<=pvalue_threshold else 0 for p in genes_df['P-value']]\n",
    "genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9624cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the differentialy expressed genes as dictionary\n",
    "def path_de_genes(path_no):\n",
    "    de_genes=np.array([])\n",
    "    for node in range(len(pvalues_dict[path_no])):\n",
    "        if(pvalues_dict[path_no][node]<=pvalue_threshold):\n",
    "            de_genes=np.append(de_genes,1)\n",
    "        else:\n",
    "            de_genes=np.append(de_genes,0)\n",
    "    return de_genes\n",
    "\n",
    "def get_de_genes(pvalues_dict):\n",
    "    de_genes={}\n",
    "    for path in pvalues_dict:\n",
    "        de_genes.update({path:path_de_genes(path)})\n",
    "    return de_genes\n",
    "\n",
    "de_genes_dict=get_de_genes(pvalues_dict)\n",
    "de_genes_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca21f1",
   "metadata": {},
   "source": [
    "# 2. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d1a49",
   "metadata": {},
   "source": [
    "## 2.1. PRS\n",
    "Each node in a pathway has three attributes: Node_genes, Node_value (NV), Node_weight (NW)\n",
    "### 2.1.1.  Development of the PRS algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada0a59",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. Node_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already calculated on 1.3.1.\n",
    "node_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a70515",
   "metadata": {},
   "source": [
    "#### 2.1.1.2. Node_value (NV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each node is assigned a value derived from expression data. The following values are assigned to the node: 0 if the \n",
    "# corresponding gene or genes are not expressed, 1 if they are expressed but remain unchanged (non-significant), or the\n",
    "# maximum fold-change value if one or more of the mapped transcripts is above threshold.\n",
    "def path_expressed_genes(log_fc,fc,pvalues):\n",
    "    expr_genes=np.array([])\n",
    "    for n in range(len(log_fc)):\n",
    "        if(log_fc[n]<log_fc_threshold): # not expressed\n",
    "            expr_genes=np.append(expr_genes,0)\n",
    "        else: # expressed\n",
    "            if(pvalues[n]>pvalue_threshold): # non-significant\n",
    "                expr_genes=np.append(expr_genes,1)\n",
    "            else: # significant\n",
    "                expr_genes=np.append(expr_genes,np.max(fc))\n",
    "    return expr_genes\n",
    "\n",
    "def Node_value(node_genes,log_fc_dict,fc_dict,pvalues_dict):\n",
    "    Node_value={}\n",
    "    \n",
    "    for path in node_genes:\n",
    "        cur_path=path_expressed_genes(log_fc_dict[path],fc_dict[path],pvalues_dict[path])\n",
    "        Node_value.update({path:cur_path})\n",
    "            \n",
    "    return Node_value\n",
    "\n",
    "node_value=Node_value(node_genes,log_fc_dict,fc_dict,pvalues_dict)\n",
    "node_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a67f998",
   "metadata": {},
   "source": [
    "#### 2.1.1.3. Node_weight (NW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4873a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate each sub-path in the form of a graph (start_node,next_node).\n",
    "def path_graph(node_value):\n",
    "    graph=[]\n",
    "    for n in range(len(node_value)-1):\n",
    "        graph.append([node_value[n],node_value[n+1]])\n",
    "    return graph\n",
    "\n",
    "def get_graph(node_value):\n",
    "    graphs={}\n",
    "    for path in node_value:\n",
    "        cur_graph=path_graph(node_value[path])\n",
    "        graphs.update({path:cur_graph})\n",
    "    return graphs\n",
    "            \n",
    "graphs=get_graph(node_value)\n",
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All significant (above-threshold) nodes were assigned a weighting that reflected\n",
    "# their topological strength (i.e., the number of significant downstream nodes that are pointed to, either\n",
    "# directly or via other significant nodes).\n",
    "# An initiating child node, n_i, was ignored if non-significant, and the algorithm proceeds to the next child.\n",
    "# Otherwise, we increase the weight counter by 1 and look for children of this node\n",
    "# and so on. All non-significant nodes have NW = 0.\n",
    "\n",
    "def sign_children(graph,weight=0):\n",
    "    threshold=1\n",
    "    if(len(graph)==0): # Reached the end\n",
    "        return weight\n",
    "    if(graph[0]<threshold):\n",
    "        return sign_children(graph[1:],weight)\n",
    "    else:\n",
    "        return sign_children(graph[1:],weight+1) # Increase weight, if the current node/child is significant\n",
    "\n",
    "def path_node_weight(node_value):\n",
    "    node_weight=[]\n",
    "    cur_weight=0\n",
    "    for node in range(len(node_value)):\n",
    "        cur_weight=sign_children(node_value[node:])\n",
    "        node_weight.append(cur_weight)\n",
    "    return node_weight\n",
    "    \n",
    "def get_node_weight(node_value):\n",
    "    node_weight={}\n",
    "    for path in node_value:\n",
    "        node_weight.update({path:path_node_weight(node_value[path])})\n",
    "    return node_weight\n",
    "       \n",
    "node_weight=get_node_weight(node_value)\n",
    "node_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bdd3e",
   "metadata": {},
   "source": [
    "#### 2.1.1.4. Node_score (NS)\n",
    "NV and NW values are combined to calculate a Node_Score (NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a85cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_node_score(NV,NW):\n",
    "    node_score=[]\n",
    "    for n in range(len(NV)):\n",
    "        if(NV[n]>1):\n",
    "            node_score.append(NV[n]*NW[n])\n",
    "        else:\n",
    "            node_score.append(0)\n",
    "    return node_score\n",
    "\n",
    "def Node_score(NV,NW):\n",
    "    node_score={}\n",
    "    for path in NV:\n",
    "        node_score.update({path:path_node_score(NV[path],NW[path])})\n",
    "    return node_score\n",
    "\n",
    "node_score=Node_score(node_value,node_weight)\n",
    "node_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5097d3",
   "metadata": {},
   "source": [
    "#### 2.1.1.5. PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_PRS(NS):\n",
    "    return sum(NS)\n",
    "\n",
    "def PRS(NS):\n",
    "    prs={}\n",
    "    for path in NS:\n",
    "        cur_sum=0\n",
    "        prs.update({path:path_PRS(NS[path])})\n",
    "    return prs\n",
    "\n",
    "prs_dict=PRS(node_score)\n",
    "prs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e671b",
   "metadata": {},
   "source": [
    "### 2.1.2. Normalizing pathway scores\n",
    "A normalization step is required to control for two key features: (i)\n",
    "pathway size and (ii) statistical bias contributed by pathway-specific PRS score null distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b49279",
   "metadata": {},
   "source": [
    "#### 2.1.2.1.  Pathway size \n",
    "Multiply each PRS score by the ratio of the number of DEGs (NDEGs) in a pathway to the total number of expressed genes (NEGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7153f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a specific pathway to control their pathway size\n",
    "def normalize_path_size(prs,node_value,NEGs):\n",
    "    NDEGs=len([element for element in node_value if element > 1]) # number of DEGs (NDEGs) in a pathway\n",
    "    return prs*(NDEGs/NEGs)\n",
    "\n",
    "def path_size_PRS(prs):\n",
    "    NEGs=len([element for element in chain.from_iterable(node_value.values()) if element > 0]) # total number of expressed genes (NEGs)\n",
    "    new_prs={}\n",
    "    for path in range(len(prs)):\n",
    "        new_prs.update({path:normalize_path_size(prs_dict[path],node_value[path],NEGs)})\n",
    "    return new_prs\n",
    "\n",
    "norm_prs_dict=path_size_PRS(prs_dict)\n",
    "norm_prs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61f3f4",
   "metadata": {},
   "source": [
    "#### 2.1.2.2. Statistical bias contributed by pathway-specific PRS score null distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9d3ae",
   "metadata": {},
   "source": [
    "##### 2.1.2.2.1. Permute fold-change values of all genes for each subpathway and create n=1000 permuted scores (pPRS).\n",
    "Permute the fold-change values of a subpath, calculate the log fold change for each new permutation and return both values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import statistics\n",
    "import random\n",
    "\n",
    "def create_permutations(fc,n=1000):\n",
    "    perm_fc=[]\n",
    "    shuffle_list_pos=list(range(len(fc)))\n",
    "    random.shuffle(shuffle_list_pos)\n",
    "    for k in range(n):\n",
    "        cur_perm_fc=[]\n",
    "        random.shuffle(shuffle_list_pos)\n",
    "        for pos in shuffle_list_pos:\n",
    "            cur_perm_fc.append(fc[pos])\n",
    "        perm_fc.append(cur_perm_fc)\n",
    "    return perm_fc\n",
    "\n",
    "# Permute the fold-change values of a subpath, calculate the log fold change for each new permutation and return both values\n",
    "def path_permute_fc(fc_dict):\n",
    "    cur_fc=fc_dict\n",
    "    \n",
    "    # Different approaches\n",
    "    #perm_fc=list(permutations(cur_fc))\n",
    "    perm_fc=list(create_permutations(cur_fc))\n",
    "    \n",
    "    # Calculate log fold change for each permutation\n",
    "    perm_log_fc=[]\n",
    "    for p in range(len(perm_fc)):\n",
    "        \n",
    "        # Convert tuple to list\n",
    "        perm_fc[p]=list(perm_fc[p])\n",
    "        \n",
    "        cur_log_fc=[]\n",
    "        for node in range(len(perm_fc[p])):\n",
    "            cur_log_fc.append(math.log(perm_fc[p][node]+1-min(genes_df['Fold Change'])))\n",
    "        perm_log_fc.append(cur_log_fc)\n",
    "    \n",
    "    return perm_fc,perm_log_fc\n",
    "\n",
    "# Create n permuted scores (pPRS)\n",
    "def path_pPRS(fc,pvalues):\n",
    "    perm_fc,perm_log_fc=path_permute_fc(fc)\n",
    "    \n",
    "    pPRS=[]\n",
    "    for p in range(len(perm_fc)):\n",
    "        NV=path_expressed_genes(perm_log_fc[p],perm_fc[p],pvalues)\n",
    "        NW=path_node_weight(NV)\n",
    "        NS=path_node_score(NV,NW)\n",
    "        pPRS.append(path_PRS(NS))\n",
    "    return pPRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a032f",
   "metadata": {},
   "source": [
    "##### 2.1.2.2.2. Standardize the raw scores (PRS) for each pathway\n",
    "# Computational time problem\n",
    "- Subtract the mean of the n permuted scores pPRS from the raw score PRS, then divide by standard deviation of the permuted scores.\n",
    "- nPRS = (PRS - mean(pPRS)) / STD(pPRS)\n",
    "- The normalized raw scores (nPRS) are considered for pathway ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_nPRS(PRS,pPRS):\n",
    "    if(statistics.stdev(pPRS)==0):\n",
    "        return 0\n",
    "    return (PRS-mean(pPRS))/statistics.stdev(pPRS)\n",
    "\n",
    "def get_nPRS(norm_prs_dict,fc_dict,pvalues_dict):\n",
    "    nPRS={}\n",
    "    for path in range(len(norm_prs_dict)):\n",
    "        print(path)\n",
    "        pPRS=path_pPRS(fc_dict[path],pvalues_dict[path])\n",
    "        nPRS.update({path:path_nPRS(norm_prs_dict[path],pPRS)})\n",
    "    return nPRS\n",
    "\n",
    "#cur_pPRS=path_pPRS(fc_dict[0],pvalues_dict[0])  \n",
    "#path_nPRS(prs_df.iloc[0]['PRS'],cur_pPRS)\n",
    "\n",
    "'''\n",
    "nPRS_dict=get_nPRS(norm_prs_dict,fc_dict,pvalues_dict)\n",
    "nPRS_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb549ea",
   "metadata": {},
   "source": [
    "### 2.1.4. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68107810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prs_df=pd.DataFrame(nPRS_dict.values(),columns=['Score'])\n",
    "prs_df=pd.DataFrame(prs_dict.values(),columns=['Score'])\n",
    "prs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bada5f0c",
   "metadata": {},
   "source": [
    "## 2.2. MinePath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52201657",
   "metadata": {},
   "source": [
    "### 2.2.1. Discretization of gene expression values\n",
    "Transform gene expression values into high (expressed / up-regulated) or low (not-expressed / down-regulated) gene expression binary equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab1db8",
   "metadata": {},
   "source": [
    "#### 2.2.1.1. The expression values of a gene over the total number of input samples are sorted in descending order;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87500a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The expression values were calculated on 1.3.2.\n",
    "genes_dis_df=genes_df.sort_values(by=['Expression Value'],ascending=False)\n",
    "genes_dis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b35c9f",
   "metadata": {},
   "source": [
    "#### 2.2.1.2. The midpoints between each two consecutive values are calculated;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(num1,num2):\n",
    "    return (num1+num2)/2\n",
    "\n",
    "midpoints_dict={} # Key corresponds to the position of the first gene. The second gene is in the next position (i+1).\n",
    "for i in range(genes_dis_df.shape[0]-1):\n",
    "    midpoints_dict.update({i:midpoint(genes_dis_df.iloc[i]['Expression Value'],genes_dis_df.iloc[i+1]['Expression Value'])})\n",
    "\n",
    "midpoints_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9dc28",
   "metadata": {},
   "source": [
    "#### 2.2.1.3. For each midpoint, μi, the Information Gain (IG) of the system is computed. Let IG(S,μi) to denote the IG of the system for midpoint μi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8483fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=sorted(set(gse2034_df.index)) # Τhe classes to which a sample may belong\n",
    "samples=gse2034_df.index # the samples class\n",
    "\n",
    "# Calculate the proportion of samples in S that belong in Class C\n",
    "def P(C,S):\n",
    "    return list(S).count(C)/len(S)\n",
    "\n",
    "def E(S,m=1):\n",
    "    # m not given: calculate the entropy of the system taking into account the prior assignment of sample cases into phenotype classes\n",
    "    # m given: calculate the respective entropy of the system taking into account its division into subgroups around midpoint μi\n",
    "    tmp=0\n",
    "    for c in classes:\n",
    "        # P(c,S) must be greater than zero\n",
    "        tmp+=P(c,S)*math.log(P(c,S))/m\n",
    "    return -(tmp)\n",
    "\n",
    "entropy=E(samples)\n",
    "print('Dataset Entropy: %.3f bits' % entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Information Gain (IG) of the system\n",
    "def IG(S,m):\n",
    "    return E(S)-E(S,m)\n",
    "\n",
    "information_gain=[]\n",
    "for m in list(midpoints_dict.values()):\n",
    "    information_gain.append(IG(samples,m))\n",
    "print('Information Gain: '+str(information_gain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The midpoint with the highest information gain is selected as the discretization point\n",
    "max_value = max(information_gain)\n",
    "max_mid_pos = information_gain.index(max(information_gain))\n",
    "dis_point=midpoints_dict.get(max_mid_pos)\n",
    "print('Discretization point: %.3f' %dis_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f1f35",
   "metadata": {},
   "source": [
    "#### 2.2.1.4. The sample cases with expression values lower than the discretization point are assigned the '0' value (meaning that the gene is under-expressed), and the sample cases with expression values bigger that the discretization point are assigned the '1' value (the gene is over-expressed).\n",
    "The discretization process is applied for each gene separately, and the final dataset is a matrix of discretized, actually binarized, values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fe3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gse2034_dis_df=gse2034_df.copy()\n",
    "gse2034_dis_df[gse2034_dis_df<dis_point]=0 # under-expressed\n",
    "gse2034_dis_df[gse2034_dis_df>=dis_point]=1 # over-expressed\n",
    "gse2034_dis_df=gse2034_dis_df.astype('int')\n",
    "gse2034_dis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7180ea4",
   "metadata": {},
   "source": [
    "### 2.2.2. Functional sub-paths: Matching sub-paths with gene expression profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52879ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "# Get the nodes of each sub-path in binary form\n",
    "gene_expression_profile_df=selected_df.copy()\n",
    "expr_prof_tmp={}\n",
    "for row in range(gene_expression_profile_df.shape[0]):\n",
    "    row_tmp=[]\n",
    "    path_tmp=gene_expression_profile_df.iloc[row][~gene_expression_profile_df.iloc[row].isnull()]\n",
    "    expr_prof_tmp[row]=[]\n",
    "    \n",
    "    for i in path_tmp[::2]:\n",
    "        tmp_node_genes=[(g.split('#')) for g in list(filter(None,i.split(' ')))] # Get genes of node\n",
    "        tmp_node_genes=list(filter(None, tmp_node_genes))\n",
    "        tmp_expr_vals=[]\n",
    "        \n",
    "        for n in tmp_node_genes:\n",
    "            # Check if gene exists in gse2034 dataset\n",
    "            if(len(n)==1):\n",
    "                if(not(n in gene_dict.values())):\n",
    "                    tmp_expr_vals.append(list(gse2034_dis_df['noProbe']))\n",
    "                    continue\n",
    "            tmp_expr_vals.append(list(gse2034_dis_df[n[0]]))\n",
    "    \n",
    "        if(len(tmp_expr_vals)>0):\n",
    "            expr_prof_tmp[row].append((np.transpose(tmp_expr_vals)).max(axis=1))\n",
    "              \n",
    "expr_prof_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7084da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace genes in pathway with their samples binary value (max value in case of multiple genes in node)\n",
    "for row in range(gene_expression_profile_df.shape[0]):\n",
    "    for column in range(0,gene_expression_profile_df.iloc[row][~gene_expression_profile_df.iloc[row].isnull()].shape[0],2):\n",
    "        # Since nodes are in the even columns, the correspondence with the positions of the table expr_prof_tmp of consecutive \n",
    "        # positions is calculated as follows: for each column c, we get c/2 (even number/2= even number)\n",
    "        gene_expression_profile_df.iat[row,column]=expr_prof_tmp[row][int(column/2)]\n",
    "        \n",
    "gene_expression_profile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions compute the 'and' and 'xor' boolean operations\n",
    "def and_boolean_op(num1,num2):\n",
    "    result=[]\n",
    "    for n in range(len(num1)):\n",
    "        result.append(num1[n]*num2[n])\n",
    "    return result\n",
    "    \n",
    "def xor_boolean_op(num1,num2):\n",
    "    result=[]\n",
    "    for n in range(len(num1)):\n",
    "        result.append(1 if(num1[n] and not num2[n]) or (not num1[n] and num2[n]) else 0)\n",
    "    return result\n",
    "\n",
    "operations_dict={'Activation':and_boolean_op,'Inhibition':xor_boolean_op}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd559e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pathway expression with boolean operations\n",
    "def calc_pathway_expression(path,prev_result):\n",
    "    if(len(path)>0):\n",
    "        t=0\n",
    "        relation=list(relations_dict.keys())[list(relations_dict.values()).index(path.iloc[0])] # Get the current edge type\n",
    "        next_node=path.iloc[1]\n",
    "        result=operations_dict[relation](prev_result,next_node)\n",
    "        calc_pathway_expression(path.iloc[2:].reset_index(drop=True),result)\n",
    "    return prev_result\n",
    "\n",
    "results=[]\n",
    "for row in range(gene_expression_profile_df.shape[0]):\n",
    "    tmp_path=gene_expression_profile_df.iloc[row][~gene_expression_profile_df.iloc[row].isnull()]\n",
    "    results.append(calc_pathway_expression(tmp_path.iloc[1:].reset_index(drop=True),tmp_path[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61979f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary sub-path expression matrix\n",
    "binary_expression_df=pd.DataFrame(results,index=list(gene_expression_profile_df.index),columns=labels)\n",
    "binary_expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make it easier to use, the resulting DataFrame is copied to a new one with the same name as the method name.\n",
    "minepath_df=binary_expression_df.copy()\n",
    "minepath_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52284cde",
   "metadata": {},
   "source": [
    "## 2.3. TAPPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea413b",
   "metadata": {},
   "source": [
    "### 2.3.1. Pathway connectivity index\n",
    "The molecular connectivity index is a widely used topological descriptor of chemical compounds and has been successfully used in many other fields, including protein structure and drug discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b19aa9",
   "metadata": {},
   "source": [
    "#### 2.3.1.1. Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c973083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adjacency matrix is defined as A=(a_ij), where a_ij=1 if i=j or (g_i, g_j) belongs to E and a_ij=0 if (g_i, g_j) does \n",
    "# not belong to E.\n",
    "def adjacency_matrix(nodes):\n",
    "    tmp_adj=[]\n",
    "    \n",
    "    #i=j -> a_ij=1\n",
    "    for i in range(len(nodes)):\n",
    "        tmp_adj.append([0]*len(nodes))\n",
    "        for j in range(len(nodes)):\n",
    "            if(i==j):\n",
    "                tmp_adj[i][j]=1\n",
    "                continue\n",
    "                \n",
    "    # (g_i,g_j) belongs to E (current sub-paths are linear) -> a_ij=1          \n",
    "    for i in range(len(nodes)-1):\n",
    "        tmp_adj[i][i+1]=1\n",
    "        tmp_adj[i+1][i]=1\n",
    "            \n",
    "    return tmp_adj\n",
    "    \n",
    "adjacency_matrices={}\n",
    "for path in node_genes:\n",
    "    adjacency_matrices.update({path:adjacency_matrix(node_genes[path])})\n",
    "adjacency_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780057e3",
   "metadata": {},
   "source": [
    "#### 2.3.1.2. Define PCI\n",
    "Assuming that x_is is the normalized log expression measurement for gene i in sample s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02542ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column expression values are normalized to zero mean.\n",
    "norm_gse2034_df=(genes_df['Expression Value']-genes_df['Expression Value'].mean())/genes_df['Expression Value'].std()\n",
    "\n",
    "# Further normalize to (-0.5,0.5) with Sigmoid function (Sigmoid (x_is) - 0.5) to lower the effects of extremely large/small \n",
    "# values for gene i in sample s.\n",
    "def sigmoid(df):\n",
    "    x=[]\n",
    "    for sample in range(df.shape[0]):\n",
    "        x.append(1 / (1 + math.exp(-df.iloc[sample])))\n",
    "    return x\n",
    "\n",
    "gene_expression_df=pd.DataFrame(sigmoid(norm_gse2034_df),columns=['Normalized log expression'],index=norm_gse2034_df.index)-0.5\n",
    "gene_expression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Each node consists of one or more genes, so each node gets the average value.\n",
    "def get_x(node_genes):\n",
    "    x={}\n",
    "    for path in node_genes:\n",
    "        cur_path=[]\n",
    "        for node in range(len(node_genes[path])):\n",
    "            cur_node=[]\n",
    "            for gene in node_genes[path][node]:\n",
    "                if(not(gene in gene_expression_df.index)):\n",
    "                    cur_node.append(gene_expression_df.loc['noProbe']['Normalized log expression'])\n",
    "                else:\n",
    "                    cur_node.append(gene_expression_df.loc[gene]['Normalized log expression'])\n",
    "            cur_path.append(mean(cur_node))\n",
    "        x.update({path:cur_path})\n",
    "    return x\n",
    "        \n",
    "# Node_genes was initialized on a previous method (PRS)\n",
    "x=get_x(node_genes)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72136233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCI(df,x,a):\n",
    "    pci_dict={}\n",
    "    for path in range(df.shape[0]):\n",
    "        cur_path=df.iloc[path][~df.iloc[path].isnull()]\n",
    "        \n",
    "        # Number of gene (ignore the edges)\n",
    "        N=len(cur_path.iloc[::2])  \n",
    "        \n",
    "        cur_sum=0\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                cur_sum+=np.sign(x[path][i]+x[path][j])*(abs(x[path][i])**0.5)*a[path][i][j]*(abs(x[path][j])**0.5)\n",
    "        \n",
    "        pci_dict.update({path:cur_sum})\n",
    "    return pci_dict\n",
    "\n",
    "pci=PCI(selected_df,x,adjacency_matrices)\n",
    "pci_df=pd.DataFrame(pci.values(),columns=['PCI'])\n",
    "pci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398651ee",
   "metadata": {},
   "source": [
    "#### 2.3.1.3. Normalize PCI (divided by the gene number in pathway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_PCI(node_genes,pci_df):\n",
    "    norm_dict={}\n",
    "    for path in range(pci_df.shape[0]):\n",
    "        cur_len=len(node_genes[path])\n",
    "        norm_dict.update({path:pci_df.iloc[path]['PCI']/cur_len})\n",
    "    return norm_dict\n",
    "\n",
    "norm_pci_df=pd.DataFrame(normalize_PCI(node_genes,pci_df).values(),columns=['Normalized PCI'])\n",
    "\n",
    "# To make it easier to use, the resulting DataFrame is copied to a new one with the method name.\n",
    "tappa_df=norm_pci_df.copy()\n",
    "tappa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f61354",
   "metadata": {},
   "source": [
    "## 2.4. HiPathia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b5904",
   "metadata": {},
   "source": [
    "### 2.4.1. Normalize the gene expression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd1549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normalization process is not defined,so the normalized gene expression values calculated for the TAPPA method are used.\n",
    "hipathia_norm_gse2034_df=gene_expression_df.copy()\n",
    "hipathia_norm_gse2034_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50ed61",
   "metadata": {},
   "source": [
    "### 2.4.2. The Hipathia mechanistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized gene expression value\n",
    "def get_u(node_genes):\n",
    "    u={}\n",
    "    for path in node_genes:\n",
    "        cur_path=[]\n",
    "        for node in range(len(node_genes[path])):\n",
    "            cur_node=[]\n",
    "            for gene in node_genes[path][node]:\n",
    "                if(not(gene in hipathia_norm_gse2034_df.index)):\n",
    "                    cur_node.append(hipathia_norm_gse2034_df.loc['noProbe']['Normalized log expression'])\n",
    "                else:\n",
    "                    cur_node.append(hipathia_norm_gse2034_df.loc[gene]['Normalized log expression'])\n",
    "            cur_path.append(mean(cur_node))\n",
    "        u.update({path:cur_path})\n",
    "    return u\n",
    "\n",
    "u=get_u(node_genes)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal intensity of each node\n",
    "def mechanistic_model(u,pathways_df):\n",
    "    s={}\n",
    "    \n",
    "    for path in range(pathways_df.shape[0]):\n",
    "        cur_path=list(pathways_df.iloc[path][~pathways_df.iloc[path].isnull()])\n",
    "        edges=list(cur_path[1::2]) # Edges are at the odd columns\n",
    "        \n",
    "        cur_s=[u[path][0]] \n",
    "        \n",
    "        for node in range(1,(len(u[path]))):\n",
    "            cur_s_a=1\n",
    "            cur_s_i=1\n",
    "            \n",
    "            for prev_node in range(node):\n",
    "                \n",
    "                # Activation signals\n",
    "                if(edges[prev_node]==relations_dict['Activation']): \n",
    "                    cur_s_a=cur_s_a*(1-cur_s[prev_node])\n",
    "                # Inhibition signals\n",
    "                else:\n",
    "                    cur_s_i=cur_s_i*(1-cur_s[prev_node])\n",
    "            \n",
    "            new_u=u[path][node]*(1-cur_s_a)*cur_s_i\n",
    "            cur_s.append(new_u)\n",
    "            \n",
    "        # Changes in the activity of the nodes will be reflected (or remain unnoticed) in the last effector node\n",
    "        s.update({path:cur_s[node]})   \n",
    "    return s\n",
    "\n",
    "s=mechanistic_model(u,selected_df)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabe3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hipathia_df=pd.DataFrame(list(s.values()),columns=['S'])\n",
    "hipathia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881eddb5",
   "metadata": {},
   "source": [
    "## 2.5. SPIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eae815",
   "metadata": {},
   "source": [
    "Two types of evidence: (i) the over-representation of DE genes in a given pathway and (ii) the abnormal perturbation of that pathway, as measured by propagating measured expression changes across the pathway topology (P_NDE,P_PERT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f44b38",
   "metadata": {},
   "source": [
    "### 2.5.1. P_NDE = P(X >= N_DE | H0)\n",
    "- Captures the significance of the given pathway Pi as provided by an over-representation analysis of the number of DE genes (N_DE) observed on the pathway.\n",
    "- N_DE: number of DE genes on the pathway analyzed\n",
    "- H0: the genes that appear as DE on a given pathway are completely random (the pathway is not relevant to the condition under study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364205a",
   "metadata": {},
   "source": [
    "#### Because of the computational time, the value of P_NDE is already calculated and transformed in csv form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_de={} # Number of DE genes on the pathway analyzed\n",
    "for path in de_genes_dict:\n",
    "    n_de.update({path:len([1 for n in de_genes_dict[path] if n])})\n",
    "\n",
    "# Already calculated\n",
    "def get_p_nde(node_value,n_de):\n",
    "    p_nde={}\n",
    "    for path in node_value:\n",
    "        # Calculating Probability of a Random Variable in a Distribution\n",
    "        p_nde.update({path:0.5 * (1 + math.erf((n_de[path] - mean(n_de.values()))/math.sqrt(2 * stdev(n_de.values()) **2)))})\n",
    "        # p_nde.update({path:n_de[path]/len(node_value[path])})\n",
    "    return p_nde\n",
    "\n",
    "#p_nde=get_p_nde(node_value,n_de) # It takes a lot of time to compute\n",
    "#p_nde_df=pd.DataFrame(p_nde.values(),index=p_nde.keys(),columns=['P_NDE'])\n",
    "#p_nde_df.to_csv(r'C:\\Users\\user\\Desktop\\ΤΕΙ\\Πτυχιακή\\Project\\Data\\P_NDE.csv',index = False, header=True) # Convert to csv for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8467e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# P_NDE is already calculated and saved is csv form because of its computational time\n",
    "p_nde_df = pd.read_csv ('Data/P_NDE.csv')\n",
    "\n",
    "# Also in dictionary form\n",
    "p_nde_dict = {p:p_nde_df.loc[p]['P_NDE'] for p in range(p_nde_df.shape[0])}\n",
    "\n",
    "p_nde_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a9347",
   "metadata": {},
   "source": [
    "### 2.5.2. P_PERT \n",
    "Calculated based on the amount of perturbation measured in each pathway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623bec70",
   "metadata": {},
   "source": [
    "#### 2.5.2.1. Gene perturbation factor (PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents the signed normalized measured expression change of the gene g_i (log fold-change if two conditions are compared)\n",
    "log_fc_dict # Calculated on 1.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sign of β reflects the type of interaction: +1 for induction (activation), −1 for repression and inhibition.\n",
    "def get_b(edges):\n",
    "    b=[]\n",
    "    for e in edges:\n",
    "        if(relations_dict['Activation']==e):\n",
    "            b.append(1)\n",
    "        else:\n",
    "            b.append(-1)\n",
    "    return b\n",
    "\n",
    "def path_pf(path,edges,log_fc):\n",
    "    # Calculate β_j\n",
    "    b=get_b(edges)\n",
    "\n",
    "    # First node \n",
    "    cur_pf=[log_fc[0]]\n",
    "\n",
    "    for i in range(1,len(path[::2])): \n",
    "        prev_pf=0\n",
    "\n",
    "        for j in range(i):\n",
    "            # The number of downstream genes of each such gene N_ds(g_j)\n",
    "            N_ds=len(path[::2])-j-1  \n",
    "\n",
    "            prev_pf+=b[j]*(cur_pf[j]/N_ds)\n",
    "\n",
    "        cur_pf.append(log_fc[i]+prev_pf)\n",
    "        \n",
    "    return cur_pf\n",
    "\n",
    "# Define gene perturbation factor\n",
    "def get_pf(log_fc_dict,pathways_df):\n",
    "    pf={}\n",
    "    \n",
    "    for path in log_fc_dict:\n",
    "        cur_path=list(pathways_df.iloc[path][~pathways_df.iloc[path].isnull()])\n",
    "        edges=list(cur_path[1::2]) # Edges are at the odd columns\n",
    "        \n",
    "        # The term ΔE(g_i) represents the signed normalized measured expression change of the gene g_i\n",
    "        cur_log_fc=log_fc_dict[path]\n",
    "    \n",
    "        cur_pf=path_pf(cur_path,edges,cur_log_fc)\n",
    "            \n",
    "        pf.update({path:cur_pf})\n",
    "    return pf\n",
    "\n",
    "pf=get_pf(log_fc_dict,selected_df)\n",
    "pf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62fbf64",
   "metadata": {},
   "source": [
    "#### 2.5.2.2. Net perturbation accumulation at the level of each gene, Acc_g\n",
    "This subtraction is needed to ensure that DE genes not connected with any other genes will not contribute to the second type of evidence since such genes are already taken into consideration in the ORA and captured by P_NDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb56818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_accumulation(pf,log_fc):\n",
    "    acc=[]\n",
    "    for node in range(len(pf)):\n",
    "        tmp_acc=pf[node]-log_fc[node]\n",
    "        acc.append(tmp_acc)\n",
    "    return acc\n",
    "        \n",
    "\n",
    "def get_acc(pf,log_fc_dict):\n",
    "    acc={}\n",
    "    for path in pf:\n",
    "        cur_acc=path_accumulation(pf[path],log_fc_dict[path])\n",
    "        acc.update({path:cur_acc})\n",
    "    return acc\n",
    "    \n",
    "acc=get_acc(pf,log_fc_dict)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ece41",
   "metadata": {},
   "source": [
    "#### 2.5.2.3. Total net accumulated perturbation in the pathway, t_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f63f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_t_A(acc):\n",
    "    return sum(acc)\n",
    "\n",
    "def get_t_A(acc):\n",
    "    t_A={}\n",
    "    for path in acc:\n",
    "        t_A.update({path:sum(acc[path])})\n",
    "    return t_A\n",
    "\n",
    "t_A=get_t_A(acc)\n",
    "t_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2791e8",
   "metadata": {},
   "source": [
    "#### 2.5.2.4. Bootstrap procedure for computing a p-value from pathway perturbations\n",
    "The probability to observe a total accumulated perturbation of the pathway, T_A, more extreme than t_A just by chance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34605f65",
   "metadata": {},
   "source": [
    "#### Because of the computational time, the value of P_PERT is already calculated and transformed in csv form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Identity function I(x): returns 1 if x is true and 0 otherwise \n",
    "def I(T_A_c,t_A_c):\n",
    "    if(t_A_c>=0):\n",
    "        if(T_A_c>=t_A_c):\n",
    "            return 1\n",
    "    else:\n",
    "        if(T_A_c<=t_A_c):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# From supplementary materials\n",
    "def path_p_pert(path_no):\n",
    "    path=list(selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()])\n",
    "    edges=list(path[1::2]) # Edges are at the odd columns\n",
    "    \n",
    "    # The data for the observed subpath\n",
    "    observed_pf=path_pf(path,edges,log_fc_dict[path_no])\n",
    "    observed_acc=path_accumulation(observed_pf,log_fc_dict[path_no])\n",
    "    observed_T_A=path_t_A(observed_acc)\n",
    "    \n",
    "    de=[n for n in range(len(de_genes_dict[path_no])) if de_genes_dict[path_no][n]] # the position of the DE genes\n",
    "    \n",
    "    N_de=len(de) # 2.1. The number of DE genes observed on the pathway with the real data\n",
    "    \n",
    "    # If the number of DE genes is 0, then we return 0\n",
    "    if(not(N_de)):\n",
    "        return 0.0\n",
    "    \n",
    "    cur_log_fc=list.copy(log_fc_dict[path_no])\n",
    "    T_A=[]\n",
    "    \n",
    "    # 1. Initialize iteration counter k (k=1)\n",
    "    for k in range(N): # k: iteration counter, N: iteration times\n",
    "        \n",
    "        # 2.2. The log fold-changes for these genes are assigned by drawing a random sample with replacement \n",
    "        # from the distribution of all DE genes ('all_de_genes')\n",
    "        new_de_pos=[]\n",
    "        for g in de:\n",
    "            tmp_de_pos=random.randint(0,len(all_de_genes)-1)\n",
    "            while tmp_de_pos in new_de_pos:\n",
    "                tmp_de_pos=random.randint(0,len(all_de_genes)-1)\n",
    "            new_de_pos.append(tmp_de_pos)\n",
    "            cur_log_fc[g]=all_de_genes[tmp_de_pos]\n",
    "\n",
    "        # 2.3. Compute the perturbation accumulations, Acc, for each gene/node in subpath\n",
    "        pf=path_pf(path,edges,cur_log_fc)\n",
    "        acc=path_accumulation(pf,cur_log_fc)\n",
    "\n",
    "        # 2.4. The net total accumulation is computed as the sum of all perturbation accumulations across each pathway (T_A(k))\n",
    "        T_A.append(sum(acc))\n",
    "    # 3. Repeat steps 2 and 3\n",
    "    \n",
    "    # 4.1. Compute the median of T_A and subtract it from T_A(k) values centering their distribution around 0\n",
    "    T_A_median=statistics.median(T_A)\n",
    "    T_A_c=[t-T_A_median for t in T_A] # Corrected values (T_A_c(k))\n",
    "    \n",
    "    # 4.2. The observed net total accumulation (T_A) is also corrected for the shift in the null distribution median to give, t_A_c\n",
    "    t_A_c=[]\n",
    "    for t in range(len(T_A)):\n",
    "        t_A_c.append(T_A[t]-T_A_c[t]) # Subtract from the observed net total accumulation (T_A) the corresponding corrected values (T_A_c)\n",
    "        \n",
    "    t_A_c=observed_T_A-statistics.median(t_A_c)\n",
    "        \n",
    "    # 5. If t_A_c is positive the pathway is activated (or positively perturbed). If t_A_c is negative then the pathway is\n",
    "    # inhibited (or negatively perturbed) --> indentity function\n",
    "    identity_sum=0\n",
    "    for k in range(N):\n",
    "        identity_sum+=I(T_A_c[k],t_A_c)\n",
    "        \n",
    "    # 6. The probability to observe such total net inhibition or activation just by chance (P_PERT)\n",
    "    p_pert=identity_sum/N\n",
    "            \n",
    "    return p_pert\n",
    "\n",
    "def p_pert():\n",
    "    p_pert={}\n",
    "    for path in node_genes:\n",
    "        print(path)\n",
    "        p_pert.update({path:path_p_pert(path)})\n",
    "    return p_pert\n",
    "    \n",
    "all_de_genes=np.array(genes_df[genes_df['DEG']==1]['Log FC']) # Log fold-change distribution of all DE genes\n",
    "N=2000 # Iteration times\n",
    "\n",
    "#p_pert=p_pert()\n",
    "#p_pert_df=pd.DataFrame(p_pert.values(),index=p_pert.keys(),columns=['P_PERT'])\n",
    "#p_pert_df.to_csv(r'C:\\Users\\Foteini Droumalia\\Desktop\\Φωτεινή Δρουμαλιά\\Project\\Data\\P_PERT.csv',index = False, header=True) # Convert to csv for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c91dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# P_PERT is already calculated and saved is csv form because of its computational time\n",
    "p_pert_df = pd.read_csv ('Data/P_PERT.csv')\n",
    "\n",
    "# Also in dictionary form\n",
    "p_pert_dict = {p:p_pert_df.loc[p]['P_PERT'] for p in range(p_pert_df.shape[0])}\n",
    "\n",
    "p_pert_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdf9eb",
   "metadata": {},
   "source": [
    "### 2.5.3. Create one DataFrame, and calculate the value of c, which is necessary for the computation of P_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spia_data_df=pd.concat([p_nde_df,p_pert_df],axis=1)\n",
    "spia_data_df['c']=spia_data_df['P_NDE']*spia_data_df['P_PERT']\n",
    "spia_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85153174",
   "metadata": {},
   "source": [
    "### 2.5.4. Global probability value, P_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_p_g(df,path_no):\n",
    "    c=df['c'].loc[path_no]\n",
    "    return c-c*np.log(c+1)\n",
    "\n",
    "def get_p_g(df):\n",
    "    p_g={}\n",
    "    for path in range(df.shape[0]):\n",
    "        p_g.update({path:path_p_g(df,path)})\n",
    "    return p_g\n",
    "\n",
    "spia_p_g=get_p_g(spia_data_df)\n",
    "spia_p_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84c89c",
   "metadata": {},
   "source": [
    "### 2.5.5. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spia_df=pd.DataFrame(spia_p_g.values(),columns=['P_G'])\n",
    "spia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838585f9",
   "metadata": {},
   "source": [
    "## 2.6. SubSPIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012a9e0",
   "metadata": {},
   "source": [
    "### 2.6.1. The statistical significance of subpathways (P_NDE)\n",
    "Two types of evidence: the overrepresentation of DEGs and the abnormal perturbation in a given subpathway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "\n",
    "def path_hypergeom(path_no):\n",
    "    t=len(list(dict.fromkeys([item for sublist in node_genes[path_no] for item in sublist]))) # Genes involved in the pathway under investigation \n",
    "    rv = hypergeom(m, t, n)\n",
    "    x = np.arange(0, t+1)\n",
    "    return rv.pmf(x)\n",
    "\n",
    "# The p-value can be calculated to evaluate enrichment significance for each pathway\n",
    "def get_pvalue(node_genes):\n",
    "    pvalue={}\n",
    "    for path in node_genes:\n",
    "        cur_hypergeom=path_hypergeom(path)\n",
    "        pvalue.update({path:(1-sum(cur_hypergeom))})\n",
    "    return pvalue\n",
    "    \n",
    "m=30000 # Total genes of human genome in the current analysis (population size)\n",
    "n=gse2034_df.shape[1] # Set of genes submitted for analysis\n",
    "\n",
    "subspia_p_nde=get_pvalue(node_genes)\n",
    "subspia_p_nde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa445b9",
   "metadata": {},
   "source": [
    "### 2.6.2. P_PERT \n",
    "Calculated in 2.5.2.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf47419",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pert_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43903659",
   "metadata": {},
   "source": [
    "### 2.6.3. Create DataFrame containing the necessary data for computing the P_G variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf247ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspia_data_df=pd.DataFrame(subspia_p_nde.values(),columns=['P_NDE'])\n",
    "subspia_data_df['P_PERT']=p_pert_dict.values()\n",
    "subspia_data_df['c']=subspia_data_df['P_NDE']*subspia_data_df['P_PERT']\n",
    "subspia_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6f7f5",
   "metadata": {},
   "source": [
    "### 2.6.4. Global probability value, P_G\n",
    "The function has already been implemented in 2.5.3. (function name: get_p_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspia_p_g=get_p_g(subspia_data_df)\n",
    "subspia_p_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7fa72",
   "metadata": {},
   "source": [
    "### 2.6.5. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a939a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subspia_df=pd.DataFrame(subspia_p_g.values(),columns=['P_G'])\n",
    "subspia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad3a8f7",
   "metadata": {},
   "source": [
    "## 2.7. DEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92e046",
   "metadata": {},
   "source": [
    "### 2.7.1. Expression data\n",
    "- Formula: E=d(μ+g)+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3480f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indicator of whether a gene is ‘on’ or ‘off’\n",
    "def get_d(pvalues,fc):\n",
    "    d=[]\n",
    "    on_genes=[]\n",
    "    for p in range(len(pvalues)):\n",
    "        # fold change > 0 indicates up-regulation and fold change < 0 indicates down-regulation of genes\n",
    "        # pvalue <= 0.05 indicates that the gene is on, else gene is off\n",
    "        if(pvalues[p]>pvalue_threshold): # Gene is off\n",
    "            d.append(0)\n",
    "        else: # Gene is on\n",
    "            on_genes.append(fc[p])\n",
    "            if(fc[p]>0): # up-regulated\n",
    "                d.append(1)\n",
    "            else: # down-regulated\n",
    "                d.append(-1)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e85765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of the absolute value of expression for ‘on’ genes (pathway effect).\n",
    "def get_m(path_no):\n",
    "    path=list.copy(node_genes[path_no])\n",
    "    m=[]\n",
    "    all_m=[]\n",
    "    total_mean=abs(gse2034_df).mean().mean()\n",
    "    for node in range(len(path)):\n",
    "        node_m=[]\n",
    "        node_all_m=[]\n",
    "        if(pvalues_dict[path_no][node]<=pvalue_threshold): # If the gene is turned on\n",
    "            m.append(abs(expression_values_dict[path_no][node])) # Get the absolute expression value of the node\n",
    "    if(len(m)):\n",
    "        return mean(m)\n",
    "    return 0 # If there are no on genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4867ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(data): # σ\n",
    "    # Number of observations\n",
    "    n = len(data)\n",
    "    # Mean of the data\n",
    "    mean = sum(data) / n\n",
    "    # Square deviations\n",
    "    deviations = [(x - mean) ** 2 for x in data]\n",
    "    # Variance\n",
    "    variance = sum(deviations) / n\n",
    "    return variance\n",
    "\n",
    "# Normal distribution\n",
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return prob_density\n",
    "\n",
    "# The variable g is assumed to come from a normal distribution with mean 0 and variance σ\n",
    "def get_g(path_no):\n",
    "    mean=0\n",
    "    s=variance(expression_values_dict[path_no])\n",
    "    if(s==0): # If the variance equals to zero, then the variable g is also zero, since division by zero is not possible. \n",
    "        g=len(expression_values_dict[path_no])*[0]\n",
    "    else:\n",
    "        g=[]\n",
    "        for node in range(len(expression_values_dict[path_no])):\n",
    "            g.append(normal_dist(expression_values_dict[path_no][node],mean,s))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e95d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_e(path_no):\n",
    "    mean=0\n",
    "    s=1\n",
    "    e=[]\n",
    "    for node in range(len(expression_values_dict[path_no])):\n",
    "        e.append(normal_dist(expression_values_dict[path_no][node],mean,s))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f928a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression data (presumably on a log scale) for each gene in a pathway was simulated using a multivariate normal distribution\n",
    "def path_E(path_no):\n",
    "    d=get_d(pvalues_dict[path_no],fc_dict[path_no])\n",
    "    m=get_m(path_no)\n",
    "    g=get_g(path_no)\n",
    "    e=get_e(path_no)\n",
    "    \n",
    "    node_E=[]\n",
    "    for node in range(len(pvalues_dict[path_no])):\n",
    "        node_E.append(d[node]*(m+g[node])+e[node])\n",
    "    return node_E\n",
    "\n",
    "def get_E(pvalues_dict,fc_dict):\n",
    "    E={}\n",
    "    for path in pvalues_dict:\n",
    "        E.update({path:path_E(path)})\n",
    "    return E\n",
    "\n",
    "#expression_data_dict=get_E(pvalues_dict,fc_dict)\n",
    "#expression_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f53ba6c",
   "metadata": {},
   "source": [
    "#### 2.7.1.1. Because of the computational time, the expression data were calculated and saved in json format for easier future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ab9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "'''\n",
    "# Write in json file\n",
    "with open('expression_data.json', 'w') as fp:\n",
    "    json.dump(expression_data_dict, fp)\n",
    "'''\n",
    "\n",
    "# Open json file\n",
    "with open('Data/expression_data.json', 'r') as fp:\n",
    "    expression_data_dict = {int(k):v for k,v in json.load(fp).items()}\n",
    "expression_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b5d94",
   "metadata": {},
   "source": [
    "### 2.7.2. Calculate differential expression\n",
    "- A recursive function calculates the differential expression for each path by adding or subtracting all downstream nodes with catalytic or inhibitory relationships, respectively.\n",
    "- The absolute value of the expression level is utilized as the DEAP score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1+(B2*relation+(B3*relation+(...)))\n",
    "def path_deap_score(path_no,path=[]): # Inputs: either the path or the number of the path as provided by the selected dataframe\n",
    "    cur_path=selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()]\n",
    "    nodes=list.copy(node_genes[path_no])\n",
    "    edges=list(cur_path[1::2])\n",
    "    \n",
    "    if(len(path)==0): # Check if there is not a specific subpath provided\n",
    "        expr_vals=list.copy(expression_data_dict[path_no])\n",
    "    else:\n",
    "        expr_vals=path\n",
    "\n",
    "    score=expr_vals[-1]\n",
    "    for n in range(len(nodes)-2,-1,-1): # Recursive: start from the final node\n",
    "        e=len(edges)-(len(nodes)-n-1)\n",
    "        if(edges[e]==relations_dict['Activation']): # Activation: +1\n",
    "            score+=(expr_vals[n]*1)\n",
    "        else: # Inhibition: -1\n",
    "            score+=(expr_vals[n]*-1)\n",
    "    return score\n",
    "    \n",
    "def get_deap_score():\n",
    "    deap_score={}\n",
    "    for path in node_genes:\n",
    "        deap_score.update({path:path_deap_score(path)})\n",
    "    return deap_score  \n",
    "deap_score_dict=get_deap_score()\n",
    "deap_score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f2a74",
   "metadata": {},
   "source": [
    "### 2.7.3. Take the absolute value from 2.7.2. as the DEAP score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bbd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_deap_score_dict={}\n",
    "for path in deap_score_dict:\n",
    "    abs_deap_score_dict.update({path:abs(deap_score_dict[path])})\n",
    "abs_deap_score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f14ce",
   "metadata": {},
   "source": [
    "### 2.7.4. Random rotation\n",
    "- Rotate data n times and recalculate DEAP score for every rotation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea73607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateList(arr,d=1):\n",
    "    n=len(arr)\n",
    "    arr[:]=arr[d:n]+arr[0:d]\n",
    "    return arr\n",
    "\n",
    "def path_random_rotation(path_no,path,score_list=[],k=0):\n",
    "    if(k==n):\n",
    "        return score_list\n",
    "    \n",
    "    if(len(score_list)==0):\n",
    "        score_list.append(deap_score_dict[path_no])\n",
    "    \n",
    "    rotated_path=rotateList(path)\n",
    "    rotated_score=path_deap_score(path_no,rotated_path)\n",
    "    \n",
    "    score_list.append(rotated_score)\n",
    "    k+=1\n",
    "    return path_random_rotation(path_no,rotated_path,score_list,k)\n",
    "\n",
    "def random_rotation(deap_score_dict):\n",
    "    random_rotation_score={}\n",
    "    for path in deap_score_dict:\n",
    "        print(path)\n",
    "        cur_path=list.copy(expression_data_dict[path])\n",
    "        random_rotation_score.update({path:mean(path_random_rotation(path,cur_path))})\n",
    "    return random_rotation_score\n",
    "\n",
    "'''\n",
    "n=1000   \n",
    "rotated_score_dict=random_rotation(deap_score_dict) \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66674910",
   "metadata": {},
   "source": [
    "### 2.7.5. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "deap_df=pd.DataFrame(abs_deap_score_dict.values(),columns=['Score'])\n",
    "deap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374eb564",
   "metadata": {},
   "source": [
    "### 2.7.5. Samples rotation: assesses statistical significance, not score (probably not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0276ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rotate array by d elements using temp array (default: 1)\n",
    "def rotateArray(arr, n, d=1):\n",
    "    temp = []\n",
    "    i = 0\n",
    "    while (i < d):\n",
    "        temp.append(arr[i])\n",
    "        i = i + 1\n",
    "    i = 0\n",
    "    while (d < n):\n",
    "        arr[i] = arr[d]\n",
    "        i = i + 1\n",
    "        d = d + 1\n",
    "    arr[:] = arr[: i] + temp\n",
    "    return arr\n",
    "\n",
    "# Score, s_i, of rotated samples for each subpath\n",
    "def path_s(path_no):\n",
    "    expr_vals=list.copy(expression_values_dict[path_no])\n",
    "    n=len(node_genes[path_no]) # Rotations\n",
    "    s=[]\n",
    "    for i in range(n):\n",
    "        s.append(path_deap_score(path_no,rotateArray(expr_vals,len(expr_vals)))) # Recompute the DEAP score for each rotation sample\n",
    "    return s    \n",
    "    \n",
    "#path_p(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69160be7",
   "metadata": {},
   "source": [
    "## 2.8. GraphiteWeb- Enrichment analysis (competitive and non-topological)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fde34",
   "metadata": {},
   "source": [
    "### 2.8.1. Probability P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18612d",
   "metadata": {},
   "source": [
    "#### 2.8.1.1. Hypergeometric Distribution \n",
    "https://towardsdatascience.com/hypergeometric-distribution-explained-with-python-2c80bc613bf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "def hypergeom_pmf(N, A, n, x):\n",
    "    \n",
    "    '''\n",
    "    Probability Mass Function for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param x: number of desired items in our draw of n items\n",
    "    :returns: PMF computed at x\n",
    "    '''\n",
    "    Achoosex = math.comb(A,x)\n",
    "    NAchoosenx = math.comb(N-A, n-x)\n",
    "    Nchoosen = math.comb(N,n)\n",
    "    \n",
    "    return (Achoosex)*NAchoosenx/Nchoosen\n",
    "\n",
    "def hypergeom_cdf(N, A, n, t, min_value=None):\n",
    "    \n",
    "    '''\n",
    "    Cumulative Density Funtion for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param t: number of desired items in our draw of n items up to t\n",
    "    :returns: CDF computed up to t\n",
    "    '''\n",
    "    if min_value:\n",
    "        return np.sum([hypergeom_pmf(N, A, n, x) for x in range(min_value, t+1)])\n",
    "    \n",
    "    return np.sum([hypergeom_pmf(N, A, n, x) for x in range(t+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3acea7",
   "metadata": {},
   "source": [
    "#### 2.8.1.2. Expression value of each gene and DEGs in every subpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe809b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_genes_expr_values(path_no):\n",
    "    expr_vals=[]\n",
    "    for node in range(len(node_genes[path_no])):\n",
    "        cur_n=[]\n",
    "        for g in node_genes[path_no][node]:\n",
    "            if(g in genes_df.index):\n",
    "                cur_n.append(genes_df.loc[g]['Expression Value'])\n",
    "            else:\n",
    "                cur_n.append(genes_df.loc['noProbe']['Expression Value'])\n",
    "        expr_vals.append(cur_n)\n",
    "    return expr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f10b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of DEGs in specific subpath\n",
    "def path_degs(path_no):\n",
    "    degs=0\n",
    "    genes=list(chain.from_iterable(node_genes[path_no])) # Remove duplicates\n",
    "    for g in genes:\n",
    "        if(not(g in genes_df.index)):\n",
    "            g='noProbe'\n",
    "        if(genes_df.loc[g]['DEG']): # If gene is differentially expressed\n",
    "            degs+=1\n",
    "    return degs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a7008",
   "metadata": {},
   "source": [
    "#### 2.8.1.3. Calculate probability P\n",
    "##### Two-way contigency table\n",
    "- DEG: differentially expressed genes\n",
    "- EEG: equally expressed genes (mean expression levels are the same across all replicates in two comparison groups)\n",
    "- N: total number of genes screened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb272ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_p(path_no):\n",
    "    expr_val=[]\n",
    "    \n",
    "    # Total\n",
    "    N_G=len(list(chain.from_iterable(node_genes[path_no]))) # Total number of genes in current subpath G\n",
    "    N_CG=N-N_G # Total number of genes in the complement of G\n",
    "    \n",
    "    # DEG\n",
    "    n_G_deg=path_degs(path_no) # Number of DEGs in subpath\n",
    "    n_CG_deg=N_deg-n_G_deg # Number of DEGs in the complement of G\n",
    "    \n",
    "    p = sum([hypergeom_cdf(N,N_deg,N_G,x,n_G_deg) for x in range(N_G+1)]) # N_G_deg>=n_G_deg\n",
    "    return p\n",
    "\n",
    "def get_p():\n",
    "    p={}\n",
    "    for path in node_genes:\n",
    "        p.update({path:path_p(path)})\n",
    "    return p\n",
    "\n",
    "# Global variables\n",
    "N=gse2034_df.shape[1] # Total number of genes screened \n",
    "N_deg=genes_df[genes_df['DEG']==1].shape[0] # Total number of DEGs\n",
    "N_eeg= N-N_deg # The genes that are not differentially expressed\n",
    "\n",
    "p_dict=get_p()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a8885",
   "metadata": {},
   "source": [
    "##### 2.8.1.3.1. Already saved in json format for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec12a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Write in json file\n",
    "'''\n",
    "with zipfile.ZipFile(\"Data/p_dict.zip\", mode=\"w\", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zip_file: \n",
    "    # Dump JSON data\n",
    "    dumped_JSON: str = json.dumps(p_dict, ensure_ascii=False, indent=4)\n",
    "    # Write the JSON data into `data.json` *inside* the ZIP file\n",
    "    zip_file.writestr(\"p_dict.json\", data=dumped_JSON)\n",
    "    # Test integrity of compressed archive\n",
    "    zip_file.testzip()\n",
    "''' \n",
    "\n",
    "# Read data from compressed json file\n",
    "with zipfile.ZipFile(\"Data/p_dict.zip\", \"r\") as z:\n",
    "        for filename in z.namelist(): \n",
    "            with z.open(filename) as f:  \n",
    "                p_dict = {int(k):v for k,v in json.load(f).items()}\n",
    "                \n",
    "p_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4659a",
   "metadata": {},
   "source": [
    "### 2.8.2. DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphiteweb_df=pd.DataFrame(p_dict.values(),columns=['P'])\n",
    "graphiteweb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd6b9",
   "metadata": {},
   "source": [
    "## 2.9. TEAK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57856f",
   "metadata": {},
   "source": [
    "### 2.9.1. Subpathway ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972f06a",
   "metadata": {},
   "source": [
    "#### 2.9.1.1. Conditional Probability Distribution\n",
    "- Node Y with m continuous parents X1,...,Xm\n",
    "- β0, ... , βm are the regression coefficients\n",
    "- σ^2 is the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression coefficients (b1=Σ[(xi-x)(yi-y)]/Σ[(xi-x)], where x and y are the mean values of x and y respectively)\n",
    "# Since our subpaths are linear, each node Y has one parent node x, and so only 2 coefficients (β0,β1).\n",
    "def estimate_coef(x, y):\n",
    "    # number of observations/points\n",
    "    n = np.size(x)\n",
    "  \n",
    "    # mean of x and y vector\n",
    "    m_x = np.mean(x)\n",
    "    m_y = np.mean(y)\n",
    "    \n",
    "    if(n==1):\n",
    "        # calculating cross-deviation and deviation about x\n",
    "        SS_xy = (y*x)[0]\n",
    "        SS_xx = (x*x)[0]\n",
    "    else:\n",
    "        # calculating cross-deviation and deviation about x\n",
    "        SS_xy = sum(y*x) - n*m_y*m_x\n",
    "        SS_xx = sum(x*x) - n*m_x*m_x\n",
    "    \n",
    "    # calculating regression coefficients\n",
    "    if(SS_xx): # If SS_xx is not zero the proceed with the division\n",
    "        b_1 = SS_xy / SS_xx\n",
    "    else: \n",
    "        b_1=0\n",
    "    b_0 = m_y - b_1*m_x\n",
    "  \n",
    "    return (b_0, b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import scipy.stats\n",
    "\n",
    "# Calculate the Conditional Probability Distribution for each node of a subpathway\n",
    "def node_cond_prob_distr(path_no,node_no,reg_coef,variance):\n",
    "    distr_mean=reg_coef[0]\n",
    "    if(node_no==0): # If current node is root (without parents), then return β0\n",
    "        return distr_mean\n",
    "    distr_mean+=reg_coef[1]*expression_values_dict[path_no][node_no-1]\n",
    "    \n",
    "    distribution = scipy.stats.norm(loc=distr_mean,scale=variance)\n",
    "    sample = distribution.rvs(size=1)[0] # linear networks: size=1\n",
    "\n",
    "    return sample\n",
    "    \n",
    "# Calculate the Conditional Probability Distribution for each subpath\n",
    "def path_cond_prob_distr(path_no):\n",
    "    path=expression_values_dict[path_no]\n",
    "    x = np.array(path[:-1]) # Continuous parents x1,...,xm\n",
    "    y = np.array(path[1:]) # Continuous nodes Y\n",
    "    \n",
    "    reg_coef=estimate_coef(y,x)\n",
    "    \n",
    "    if(len(y)>1):\n",
    "        variance=statistics.variance(y)\n",
    "    else:\n",
    "        variance=y[0]\n",
    "        \n",
    "    cond_prob=[]\n",
    "    for node in range(len(path)):\n",
    "        cond_prob.append(node_cond_prob_distr(path_no,node,reg_coef,variance))\n",
    "        \n",
    "    return cond_prob\n",
    "    \n",
    "def get_cond_prob_distr():\n",
    "    cond_prob_distr={}\n",
    "    for path in expression_values_dict:\n",
    "        cond_prob_distr.update({path:path_cond_prob_distr(path)})\n",
    "    return cond_prob_distr\n",
    "    \n",
    "cond_prob_distr_dict=get_cond_prob_distr()\n",
    "cond_prob_distr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d8cd0",
   "metadata": {},
   "source": [
    "#### 2.9.1.2. Score_BIC=logP(D|θ)-0.5d*logN\n",
    "- D: gene expression data\n",
    "- θ: maximum likelihood estimate of the parameters used to represent the linear Gaussian node\n",
    "- d: number of parameters\n",
    "- N: number of samples in the gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_score_BIC(path_no,node_no):\n",
    "    if(node_no==0): # If the current node is root (without parent node)\n",
    "        return math.log(cond_prob_distr_dict[path_no][node_no]+1-min(cond_prob_distr_dict[path_no])) # Only 1 parent node\n",
    "    \n",
    "    # Else: All other nodes have only 1 parent node (d=1)\n",
    "    N=genes_df.shape[0]\n",
    "    \n",
    "    # Logarithm of negative values: Translate, then Transform (log(Y + 1 - min(Y)))\n",
    "    # Source: https://blogs.sas.com/content/iml/2011/04/27/log-transformations-how-to-handle-negative-data-values.html\n",
    "    score=math.log(cond_prob_distr_dict[path_no][node_no]+1-min(cond_prob_distr_dict[path_no]))-0.5*math.log(N)\n",
    "    return score\n",
    "\n",
    "def path_score_BIC(path_no):\n",
    "    score=[]\n",
    "    for node in range(len(expression_values_dict[path_no])):\n",
    "        score.append(node_score_BIC(path_no,node))\n",
    "    \n",
    "    # Sum all nodes' scores and return final result\n",
    "    return sum(score)\n",
    "\n",
    "def get_score_BIC():\n",
    "    score={}\n",
    "    for path in expression_values_dict:\n",
    "        score.update({path:path_score_BIC(path)})\n",
    "    return score\n",
    "    \n",
    "score_BIC=get_score_BIC()\n",
    "score_BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1b7dc",
   "metadata": {},
   "source": [
    "#### 2.9.1.3. Normalize scores\n",
    "The score for each subpathway is normalized by its number of nodes, so that the scores are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_scores(scores):\n",
    "    normalized_scores={}\n",
    "    for path in scores:\n",
    "        normalized_scores.update({path:scores[path]/len(node_genes[path])})\n",
    "    return normalized_scores\n",
    "\n",
    "norm_score_BIC=get_normalized_scores(score_BIC)\n",
    "norm_score_BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df013fc",
   "metadata": {},
   "source": [
    "### 2.9.2. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab752f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teak_df=pd.DataFrame(norm_score_BIC.values(),columns=['Score'])\n",
    "teak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963830b",
   "metadata": {},
   "source": [
    "# 3. Significance (Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32924144",
   "metadata": {},
   "source": [
    "## 3.1. Data normalization\n",
    "- Rescaling real-valued numeric attributes into a 0 to 1 range.\n",
    "- Makes model training less sensitive to the scale of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f138ebd",
   "metadata": {},
   "source": [
    "### 3.1.1. Create a DataFrame, where rows are the subpaths and columns are the methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38901192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In MinePath's case, for temporary use, the mean value of samples is calculated and assigned as the subpath score\n",
    "minepath_df['Mean']=minepath_df.mean(axis=1)\n",
    "\n",
    "methods={'PRS':prs_df,'MinePath':minepath_df['Mean'].to_frame(),'TAPPA':tappa_df,'HiPathia':hipathia_df,'SPIA':spia_df,'SubSPIA':subspia_df,'DEAP':deap_df,'GraphiteWeb':graphiteweb_df,'TEAK':teak_df}\n",
    "\n",
    "# Rename columns as the name of the Method\n",
    "for m in methods:\n",
    "    methods[m].rename(columns={list(methods[m].columns)[0]:m},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b41dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df=pd.concat(list(methods.values()),axis=1)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61a729",
   "metadata": {},
   "source": [
    "### 3.1.2. Normalize data (min-max normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f424180",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_scores_df=(scores_df-scores_df.min())/(scores_df.max()-scores_df.min())\n",
    "normalized_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51628221",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_scores_df['Mean']=normalized_scores_df.mean(axis=1)\n",
    "normalized_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa22fc",
   "metadata": {},
   "source": [
    "Basic steps (?)\n",
    "1. Find the index of cancer-related subpaths in selected_df.\n",
    "2. Get the score of each method for the subpaths selected in step 1.\n",
    "3. Based on the score value, assign a value indicating whether the subpath is significant or not for each method. (score<=0.05, like p-value?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0d2e0",
   "metadata": {},
   "source": [
    "## 3.2. Evaluate Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e142b",
   "metadata": {},
   "source": [
    "### 3.2.1. Prepare data\n",
    "- Samples (rows) and Sub-paths (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "subpaths=np.array(selected_df.index)\n",
    "subpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a298535",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=gse2034_df.index\n",
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
