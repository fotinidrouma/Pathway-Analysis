{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9497ce42",
   "metadata": {},
   "source": [
    "# Main script\n",
    "## Main idea:\n",
    "- Each method is implemented for a specific sample and a specific sub-path. \n",
    "- Because of the large number of data available, we compute the score of a specific sub-path (path_no = 0) and each sample.\n",
    "- In the end, each methodology will be applied to each sample and subpathway using iterative methods.\n",
    "- Current results: DataFrame of each method, where rows are samples and column is sub-path #0\n",
    "\n",
    "## Ideas: \n",
    "- Each tool could be implemented in another file and then be imported as a complete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For examples\n",
    "sample_no=0\n",
    "path_no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e738e5",
   "metadata": {},
   "source": [
    "# 1. Read data and make them easier to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57656cb",
   "metadata": {},
   "source": [
    "## 1.1. GSE2034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5989ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gse2034_df = pd.read_csv('Data/GSE2034.zip', compression='zip', header=0, sep='\\t', quotechar='\"') # Breast cancer\n",
    "gse2034_df=raw_gse2034_df.copy()\n",
    "\n",
    "# preprocess dataset\n",
    "gse2034_df[['Gene','KEGG-ID']] = gse2034_df['Class'].str.split('#',expand=True)\n",
    "gse2034_df.drop('Class', inplace=True, axis=1)\n",
    "cols = gse2034_df.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "gse2034_df=gse2034_df[cols]\n",
    "\n",
    "#gse2034_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6eeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names (estrogen receptor)\n",
    "labels=gse2034_df.columns[2:]\n",
    "for x in range(len(labels)):\n",
    "    if(labels[x].startswith('ERpos')):\n",
    "        labels.values[x]=\"ERpos\"\n",
    "    elif(labels[x].startswith('ERneg')):\n",
    "        labels.values[x]=\"ERneg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the genes that are present in the GSE2034 dataset and create a dictionary \n",
    "# where the keys are the genes and the values are the corresponding KEGG-IDs\n",
    "# 'a gene can be mapped to more than one Entrez identifier'\n",
    "gene_list=sorted(set(gse2034_df['Gene'].tolist()))\n",
    "gene_dict={}\n",
    "for i in gene_list:\n",
    "    tmp=(gse2034_df.loc[gse2034_df['Gene'] == i]['KEGG-ID']).copy()\n",
    "    tmp_list=[]\n",
    "    for t in tmp:\n",
    "        tmp_list.append(t)\n",
    "    gene_dict.update({i:tmp_list})\n",
    "#print('Gene dictionary (key: Genes, values: KEGG-IDs): '+str(gene_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a650f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose dataframe so that the columns indicate the genes\n",
    "# and rows correspond to samples (class: ERpos or ERneg)\n",
    "genes=(gse2034_df['Gene']).copy()\n",
    "gse2034_df.drop('KEGG-ID', inplace=True, axis=1)\n",
    "gse2034_df=np.transpose(gse2034_df.iloc[:,1:])\n",
    "gse2034_df.columns=genes.values.tolist()\n",
    "#gse2034_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c51df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because one gene might correspond to more than one KEGG-IDs, we calculate the average (or max)\n",
    "# value and get the following simplified dataframe\n",
    "gse2034_df=gse2034_df.groupby(level=0,axis=1).mean()\n",
    "gse2034_df['noProbe']=gse2034_df.mean(axis=1) # Compute 'noProbe' for future use\n",
    "genes=gse2034_df.columns\n",
    "gse2034_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069820e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=gse2034_df.index\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4369b15",
   "metadata": {},
   "source": [
    "## 1.2. Selected\n",
    "Cellular processes (15), Signal transduction (Environmental information process) (24), Cancer overview (8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44183827",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_selected_df = pd.read_csv('Data/Selected.zip', compression='zip', header=0, sep='\\t', quotechar='\"')[['SubPathID']]\n",
    "#raw_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of nodes relations\n",
    "relations_dict={'Activation':'-->','Inhibition':'--|'}\n",
    "#relations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb66f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Split each pathway based on the relation\n",
    "def split_path(data,relation):\n",
    "    s=[]\n",
    "    cnt=len(data.split(relations_dict[relation]))\n",
    "    cnt_tmp=1\n",
    "    # If there is at least one relation, then split data\n",
    "    if(cnt>0):\n",
    "        for e in data.split(relations_dict[relation]):\n",
    "            if e:\n",
    "                s.append(e)\n",
    "                # Remove the final relation\n",
    "                if(cnt_tmp<cnt):\n",
    "                    s.append(relations_dict[relation])\n",
    "                cnt_tmp+=1\n",
    "    return s\n",
    "\n",
    "# Make the selected dataset easier to understand, by splitting each pathway based on their nodes and edges\n",
    "def get_pathway(data):\n",
    "    s=split_path(data,'Activation')\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        tmp_s=split_path(s[i],'Inhibition')\n",
    "        if(len(s[i])>1):\n",
    "            s[i]=tmp_s\n",
    "            \n",
    "    return list(chain.from_iterable(s))\n",
    "\n",
    "subpaths_list=[get_pathway(row) for row in raw_selected_df['SubPathID']]\n",
    "#subpaths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df=pd.DataFrame(subpaths_list).fillna(value=np.nan) # Rows: pathways, Cols: edges and nodes\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47462127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of nodes relations\n",
    "relations_dict={'Activation':'-->','Inhibition':'--|'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2692be",
   "metadata": {},
   "source": [
    "## 1.3. Important values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046d110",
   "metadata": {},
   "source": [
    "### 1.3.1. Node genes- all genes of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9546bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each node in a pathway represents a discrete function mapping to one or more transcript.\n",
    "# Returns a dictionary corresponding each node of each pathway to its gene or genes.\n",
    "def Node_genes(df):\n",
    "    Node_genes={}\n",
    "    for path in range(df.shape[0]):\n",
    "        tmp_node=[]\n",
    "        for node in range(0,len(df.iloc[path][~df.iloc[path].isnull()]),2):\n",
    "            genes=list(filter(None,[x.strip() for x in df.iloc[path,node].split(' ')]))\n",
    "            tmp_genes=[]\n",
    "            for g in genes:\n",
    "                tmp_genes.append(list(filter(None,[x.strip() for x in g.split('#')]))[0])\n",
    "            tmp_node.append(tmp_genes)\n",
    "        Node_genes.update({path:tmp_node})\n",
    "    return Node_genes\n",
    "\n",
    "node_genes=Node_genes(selected_df)\n",
    "node_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f17d6d",
   "metadata": {},
   "source": [
    "### 1.3.2. Expression value\n",
    "For each subpath assign each sample's genes expression values (3D: samples,subpaths,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1354b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# For a specific subpath match the expression values of each gene based on the values in a specific sample.\n",
    "# In case of multiple genes in one node assign the average value.\n",
    "def sample_expression_value(path,sample):\n",
    "    sample_expr_val=[]\n",
    "    for node in range(len(path)):\n",
    "        node_genes=[]\n",
    "        for gene in range(len(path[node])):\n",
    "            node_genes.append(sample[gene])\n",
    "        sample_expr_val.append(mean(node_genes)) # Calculate the average expression value of a node's genes\n",
    "    return sample_expr_val\n",
    "\n",
    "#sample_no=0\n",
    "#path_no=0\n",
    "#sample_expression_value(node_genes[path_no],gse2034_df.iloc[sample_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific subpath assign the expression values based on each sample and return a 2D array\n",
    "def subpath_expression_value(path,samples):\n",
    "    \n",
    "    # Create a 2D array, where rows are the sample size and columns are the subpath's nodes\n",
    "    subpath_expr_val=[]\n",
    "    \n",
    "    # For each sample\n",
    "    for sample in range(samples.shape[0]):\n",
    "        subpath_expr_val.append(sample_expression_value(path,samples.iloc[sample]))\n",
    "        \n",
    "    return subpath_expr_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4693c",
   "metadata": {},
   "source": [
    "Because of the time complexity, the expression value is calculated only for one subpath and each training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_no=0\n",
    "subpath_expr_val=subpath_expression_value(node_genes[path_no],gse2034_df)\n",
    "subpath_expr_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33895237",
   "metadata": {},
   "source": [
    "### 1.3.3. P-value and threshold <= 0.05 (gene is significant)\n",
    "For each gene find the p-value (ttest_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "#gse2034_df2=gse2034_df.copy().T # Columns: samples and rows: genes\n",
    "#gse2034_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3dffa0",
   "metadata": {},
   "source": [
    "#### 1.3.3.1. For each gene find cancer and normal mean value and calculate their difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ad2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gse2034_df2['ERnegMean']=gse2034_df2['ERneg'].mean(axis=1)\n",
    "#gse2034_df2['ERposMean']=gse2034_df2['ERpos'].mean(axis=1)\n",
    "#gse2034_df2['Diffs']=gse2034_df2['ERnegMean']-gse2034_df2['ERposMean']\n",
    "#gse2034_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvalue005(genes):\n",
    "    pvalArray=np.empty(genes.shape[0])\n",
    "    pvalArrayUnder005=np.array([])\n",
    "    indices005=np.array([])\n",
    "    for x in range(genes.shape[0]):\n",
    "        st,pval=stats.ttest_ind(genes['ERneg'].iloc[x],genes['ERpos'].iloc[x])\n",
    "        pvalArray[x]=pval\n",
    "        if(pval<0.05):\n",
    "            pvalArrayUnder005=np.append(pvalArrayUnder005,pval)\n",
    "            indices005=np.append(indices005,x)\n",
    "    return pvalArray,pvalArrayUnder005,indices005\n",
    "\n",
    "#pvalList2,pvalListUnder005_2,indices005_2=pvalue005(gse2034_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb021e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gse2034_df2['P-Value']=pvalList2\n",
    "#gse2034_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each node of a sub-path consisting of more than one genes, get the average value of the p-values.\n",
    "def path_pvalue(path,df):\n",
    "    cur_path=[]\n",
    "    for node in path:\n",
    "        cur_node=[]\n",
    "        for gene in node:\n",
    "            # Check if gene is not in genes' list\n",
    "            if(not(gene in df.index)):\n",
    "                cur_node.append(df.loc['noProbe']['P-Value'])\n",
    "                continue\n",
    "            cur_node.append(df.loc[gene]['P-Value'])\n",
    "        cur_path.append(np.mean(cur_node))\n",
    "    return cur_path\n",
    "         \n",
    "def get_pvalues(node_genes,df):\n",
    "    pvalues={}\n",
    "    for path in node_genes:\n",
    "        pvalues.update({path:path_pvalue(node_genes[path],df)})  \n",
    "    return pvalues\n",
    "\n",
    "pvalue_threshold=0.05\n",
    "\n",
    "#pvalues_dict=get_pvalues(node_genes,gse2034_df2) # All sub-paths\n",
    "#pvalues_dict\n",
    "\n",
    "#pvalues=path_pvalue(node_genes[path_no],gse2034_df2) # One sub-path\n",
    "#pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d9e53",
   "metadata": {},
   "source": [
    "### 1.3.4. Fold Change and Log Fold Change\n",
    "Add fold change column to genes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fold change for each gene\n",
    "def fold_change(df):\n",
    "    fc_dict={}\n",
    "    \n",
    "    for gene in df.index:\n",
    "        # Get average value for each case\n",
    "        erneg_av=df.loc[gene]['ERneg'].mean()\n",
    "        erpos_av=df.loc[gene]['ERpos'].mean()\n",
    "        \n",
    "        # Calculate fold change (B/A)\n",
    "        cur_fc=erneg_av/erpos_av\n",
    "        fc_dict.update({gene:cur_fc})\n",
    "        \n",
    "    return fc_dict        \n",
    "\n",
    "#fc=fold_change(gse2034_df2)\n",
    "#gse2034_df2['Fold Change']=fold_change(gse2034_df2).values()\n",
    "#gse2034_df2['Log FC']=[math.log(fc+1-min(gse2034_df2['Fold Change'])) for fc in gse2034_df2['Fold Change']] # Calculate log fold change\n",
    "#gse2034_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each node of a sub-path consisting of more than one genes, get the average value of the fold change.\n",
    "def path_fc(path,df):\n",
    "    fc=[]\n",
    "    log_fc=[]\n",
    "    for node in path:\n",
    "        cur_fc=[]\n",
    "        cur_log_fc=[]\n",
    "        for gene in node:\n",
    "            # Check if gene is not in genes' list\n",
    "            if(not(gene in df.index)):\n",
    "                cur_fc.append(df.loc['noProbe']['Fold Change'])\n",
    "                cur_log_fc.append(df.loc['noProbe']['Log FC'])\n",
    "                continue\n",
    "            cur_fc.append(df.loc[gene]['Fold Change'])\n",
    "            cur_log_fc.append(df.loc[gene]['Log FC'])\n",
    "        fc.append(np.mean(cur_fc))\n",
    "        log_fc.append(np.mean(cur_log_fc))\n",
    "    return fc,log_fc\n",
    "            \n",
    "\n",
    "def get_fc(node_genes,df):\n",
    "    fc={}\n",
    "    log_fc={}\n",
    "    for path in node_genes:\n",
    "        cur_fc,cur_log_fc=path_fc(node_genes[path],df)\n",
    "        fc.update({path:cur_fc})  \n",
    "        log_fc.update({path:cur_log_fc})  \n",
    "    return fc,log_fc\n",
    "\n",
    "log_fc_threshold=1.5 \n",
    "\n",
    "#fc_dict,log_fc_dict=get_fc(node_genes,gse2034_df2) # Return fold change and log fold change in dictionary form for all sub-paths\n",
    "\n",
    "#fc,log_fc=path_fc(node_genes[path_no],gse2034_df2) # Specific sub-path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd603dd",
   "metadata": {},
   "source": [
    "### 1.3.5. Extract the DataFrame for future use and create dictionaries for sub-paths based on the previous implemented functions\n",
    "- Values from 2.3.3. to 2.3.4. are extracted to GSE2034_data.csv so they don't have to be computed every time.\n",
    "- Create the dictionaries for each subpath using the GSE2034_data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gse2034_df2.to_csv(r'C:\\Users\\Foteini Droumalia\\Desktop\\Φωτεινή Δρουμαλιά\\Project\\data\\GSE2034_data.csv',header=True)\n",
    "gse2034_df2 = pd.read_csv ('Data\\GSE2034_data.csv').iloc[:,1:]\n",
    "new_columns=list(gse2034_df.index)+list(gse2034_df2.columns[-6:])\n",
    "gse2034_df2.columns=new_columns\n",
    "gse2034_df2.index=genes\n",
    "gse2034_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec21aa2",
   "metadata": {},
   "source": [
    "#### 1.3.5.1. P-Value corresponding to each path's nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues=path_pvalue(node_genes[path_no],gse2034_df2) # Specific sub-path\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddcaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_dict=get_pvalues(node_genes,gse2034_df2) # All sub-paths\n",
    "pvalues_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0f912",
   "metadata": {},
   "source": [
    "#### 1.3.5.2. Fold-Change and Log fold-Change corresponding to each path's nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc,log_fc=path_fc(node_genes[path_no],gse2034_df2) # Specific sub-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223144dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_dict,log_fc_dict=get_fc(node_genes,gse2034_df2) # Return fold change and log fold change in dictionary form for all sub-paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3562722",
   "metadata": {},
   "source": [
    "### 1.3.6. Differentially Expressed Genes (DEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecce24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the differentialy expressed genes of a specific sub-path\n",
    "def path_de_genes(pvalues):\n",
    "    de_genes=[]\n",
    "    for node in range(len(pvalues)):\n",
    "        if(pvalues[node]<=pvalue_threshold):\n",
    "            de_genes.append(1)\n",
    "        else:\n",
    "            de_genes.append(0)\n",
    "    return de_genes\n",
    "\n",
    "# Get the differentially expressed genes of all sub-paths in dictionary form\n",
    "def get_de_genes(pvalues_dict):\n",
    "    de_genes={}\n",
    "    for path in pvalues_dict:\n",
    "        de_genes.update({path:path_de_genes(pvalues_dict[path])})\n",
    "    return de_genes\n",
    "\n",
    "de_genes=path_de_genes(pvalues) # Specific sub-path\n",
    "de_genes_dict=get_de_genes(pvalues_dict) # All sub-paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fe9e0",
   "metadata": {},
   "source": [
    "## 1.3.7. Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383276db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for each gene and sample the z-score and determine the threshold.\n",
    "\n",
    "import scipy.stats as stats\n",
    "z_threshold=1.96\n",
    "z_score_df=stats.zscore(gse2034_df, axis=1)\n",
    "z_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4951525b",
   "metadata": {},
   "source": [
    "# 2. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250c617",
   "metadata": {},
   "source": [
    "## 2.1. MinePath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d249c7",
   "metadata": {},
   "source": [
    "### 2.1.1. Discretization of gene expression values\n",
    "Transform gene expression values into high (expressed / up-regulated) or low (not-expressed / down-regulated) gene expression binary equivalents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3e4dd",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. The midpoints between each two consecutive values are calculated;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(num1,num2):\n",
    "    return (num1+num2)/2\n",
    "\n",
    "# Returns the midpoints for a specific gene\n",
    "def gene_midpoints(gene):\n",
    "    tmp_gene=gene.copy()\n",
    "    tmp_gene=tmp_gene.reset_index().drop(['index'],axis=1) # Keep previous positions\n",
    "    \n",
    "    # The expression values of a gene over the total number of input samples are sorted in descending order;\n",
    "    sorted_gene=(tmp_gene/tmp_gene.shape[0]).sort_values(by=gene.name,ascending=False)\n",
    "    \n",
    "    midpoints_dict={}\n",
    "    for i in range(sorted_gene.shape[0]-1):\n",
    "        midpoints_dict.update({sorted_gene.index[i]:midpoint(sorted_gene.iloc[i][gene.name],sorted_gene.iloc[i+1][gene.name])})\n",
    "    return midpoints_dict\n",
    "\n",
    "# Returns the midpoints for all the samples\n",
    "def get_midpoints(df):\n",
    "    midpoints=[] \n",
    "    for gene in range(df.shape[1]):\n",
    "        midpoints.append(gene_midpoints(df.iloc[:,gene]))\n",
    "    return midpoints_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45e496",
   "metadata": {},
   "source": [
    "#### 2.1.1.2. For each midpoint, μi, the Information Gain (IG) of the system is computed. Let IG(S,μi) to denote the IG of the system for midpoint μi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "# Calculate the proportion of samples in S that belong in Class C\n",
    "def P(C,S):\n",
    "    return list(S).count(C)/len(S)\n",
    "\n",
    "def E(S,classes,m=1):\n",
    "    # m not given: calculate the entropy of the system taking into account the prior assignment of sample cases into phenotype classes\n",
    "    # m given: calculate the respective entropy of the system taking into account its division into subgroups around midpoint μi\n",
    "    tmp=0\n",
    "    for c in classes:\n",
    "        # P(c,S) must be greater than zero\n",
    "        tmp+=P(c,S)*math.log(P(c,S))/m\n",
    "    return -(tmp)\n",
    "\n",
    "# Calculate the Information Gain (IG) of the system\n",
    "def gene_IG(gene,midpoints):\n",
    "    classes=sorted(set(gene.index))\n",
    "    S=gene.index # the samples class\n",
    "    \n",
    "    information_gain={}\n",
    "    for m in midpoints:\n",
    "        information_gain.update({m:E(S,classes)-E(S,classes,midpoints[m])})\n",
    "    \n",
    "    return information_gain\n",
    "\n",
    "# Calculate the Information Gain (IG) of the system\n",
    "def IG(df):\n",
    "    new_df=df\n",
    "    information_gain={}\n",
    "    for gene in new_df.columns:\n",
    "        information_gain.update({gene:gene_IG(df[gene])})\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03efe91",
   "metadata": {},
   "source": [
    "#### 2.1.1.3. The sample cases with expression values lower than the discretization point are assigned the '0' value (meaning that the gene is under-expressed), and the sample cases with expression values bigger that the discretization point are assigned the '1' value (the gene is over-expressed).\n",
    "The discretization process is applied for each gene separately, and the final dataset is a matrix of discretized, actually binarized, values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization_point(midpoints,information_gain):\n",
    "    # The midpoint with the highest information gain is selected as the discretization point\n",
    "    max_value=max(information_gain.values())\n",
    "    max_mid_pos = max(information_gain, key=information_gain.get)\n",
    "    dis_point=midpoints.get(max_mid_pos)\n",
    "    return dis_point\n",
    "\n",
    "def gene_discretization(gene):\n",
    "    midpoints=gene_midpoints(gene)\n",
    "    information_gain=gene_IG(gene,midpoints)\n",
    "    dis_point=discretization_point(midpoints,information_gain)\n",
    "    \n",
    "    gene_dis=gene.copy()\n",
    "    gene_dis[gene_dis<dis_point]=0 # under-expressed\n",
    "    gene_dis[gene_dis>=dis_point]=1 # over-expressed\n",
    "    gene_dis=gene_dis.astype('int')\n",
    "    \n",
    "    return gene_dis\n",
    "\n",
    "def discretization(genes):\n",
    "    dis_genes={}\n",
    "    k=1\n",
    "    for gene in genes.columns:\n",
    "        print(k*100/len(genes.columns))\n",
    "        k+=1\n",
    "        dis_genes.update({gene:list(gene_discretization(genes[gene]))})\n",
    "    return dis_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute discretized gene expression values\n",
    "#dis_gse2034_df=pd.DataFrame(discretization(gse2034_df),index=gse2034_df.index)\n",
    "#dis_gse2034_df.to_csv('Data/MinePath_discr_data.csv',index=False)\n",
    "dis_gse2034_df=pd.read_csv ('Data/MinePath_discr_data.csv')\n",
    "dis_gse2034_df.index=gse2034_df.index\n",
    "dis_gse2034_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220eb7ff",
   "metadata": {},
   "source": [
    "### 2.1.2. Functional sub-paths: Matching sub-paths with gene expression profiles\n",
    "Due to the large volume of data, we refer only to one patient and in the future we will apply the analysis to the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4418647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "# Get the nodes of a specific sub-path and sample in binary form\n",
    "def sample_functional_subpath(sample,path):\n",
    "    expr_prof=[]\n",
    "    for node in path:\n",
    "        tmp_node=[]\n",
    "        for gene in node:\n",
    "            if(~(gene in sample.index)):\n",
    "                tmp_node.append(sample['noProbe'])\n",
    "                continue\n",
    "            tmp_node.append(sample[gene])\n",
    "        expr_prof.append(statistics.mean(tmp_node))\n",
    "    return expr_prof\n",
    "\n",
    "#funct_subpath_0=sample_functional_subpath(dis_gse2034_df.iloc[sample_no],node_genes[0])\n",
    "#funct_subpath_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b479fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions compute the 'and' and 'xor' boolean operations\n",
    "def and_boolean_op(num1,num2):\n",
    "    return num1*num2\n",
    "    \n",
    "def xor_boolean_op(num1,num2):\n",
    "    return 1 if(num1 and not num2) or (not num1 and num2) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pathway expression of a specific sample and sub-path with boolean operations\n",
    "def calc_pathway_expression(path,edges,prev_result):\n",
    "    operations_dict={'Activation':and_boolean_op,'Inhibition':xor_boolean_op}\n",
    "    \n",
    "    # Two types of nodes relations\n",
    "    relations_dict={'Activation':'-->','Inhibition':'--|'}\n",
    "    \n",
    "    if(len(path)>1):\n",
    "        relation=list(relations_dict.keys())[list(relations_dict.values()).index(edges[0])] # Get the current edge type\n",
    "        next_node=path[1]\n",
    "        result=operations_dict[relation](prev_result,next_node)\n",
    "        calc_pathway_expression(path[1:],edges[1:],result)\n",
    "    return prev_result\n",
    "\n",
    "# Calculate a specific sub-path's expression for each sample with boolean operations\n",
    "def calc_all_samples_expression(path,edges,samples):\n",
    "    subpath_expr=[]\n",
    "    for sample in range(samples.shape[0]):\n",
    "        funct_subpath=sample_functional_subpath(samples.iloc[sample],path)\n",
    "        subpath_expr.append(calc_pathway_expression(funct_subpath,edges,funct_subpath[0]))\n",
    "    return subpath_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific sub-path and each sample calculate the sub-path's expression \n",
    "# Rows: samples, column: pathway #0\n",
    "'''\n",
    "path_no=0\n",
    "path=node_genes[path_no]\n",
    "edges=list(selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()][1::2])\n",
    "subpath_0_expression=calc_all_samples_expression(path,edges,dis_gse2034_df)\n",
    "    \n",
    "print('Expression of sub-path #%d : %s'%(path_no,subpath_0_expression))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sample and each sub-path calculate the sub-paths' expression\n",
    "'''\n",
    "subpaths_expression={}\n",
    "for path in node_genes:\n",
    "    print((path+1)*100/len(node_genes))\n",
    "    cur_path=node_genes[path]\n",
    "    edges=list(selected_df.iloc[path][~selected_df.iloc[path].isnull()][1::2])\n",
    "    sample_expression=[]\n",
    "    for sample in range(dis_gse2034_df.shape[0]):\n",
    "        funct_subpath=sample_functional_subpath(dis_gse2034_df.iloc[sample],cur_path)\n",
    "        sample_expression.append(calc_pathway_expression(funct_subpath,edges,funct_subpath[0]))\n",
    "    subpaths_expression.update({path:sample_expression})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b5558",
   "metadata": {},
   "source": [
    "## 2.1.3. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc.\n",
    "The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def minepath_5(selected_df,node_genes,dis_gse2034_df,already_calculated,percentage=0.05):\n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    minepath_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(selected_df.shape[0]*0.05))\n",
    "        i+=1\n",
    "        edges=list(selected_df.iloc[path][~selected_df.iloc[path].isnull()][1::2])\n",
    "        minepath_scores.append(calc_all_samples_expression(node_genes[path],edges,dis_gse2034_df))\n",
    "    \n",
    "    prev_minepath_df = pd.read_csv ('Results/MinePath.csv')\n",
    "    prev_minepath_df.index=gse2034_df.index\n",
    "    \n",
    "    tmp_minepath_df=pd.DataFrame(np.array(minepath_scores).T, columns=new_cols)\n",
    "    tmp_minepath_df.index=gse2034_df.index\n",
    "    \n",
    "    new_minepath_df=pd.concat([prev_minepath_df, tmp_minepath_df], axis=1)\n",
    "    new_minepath_df.to_csv('Results/MinePath.csv',index=False) # Already computed\n",
    "    \n",
    "#percentage=0.05\n",
    "#times=1/percentage\n",
    "#for t in range(times+1):\n",
    "#    minepath_5(selected_df,node_genes,dis_gse2034_df,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minepath_df = pd.read_csv ('Results/MinePath.csv')\n",
    "minepath_df.index=gse2034_df.index\n",
    "minepath_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd92354",
   "metadata": {},
   "source": [
    "## 2.2. TAPPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b721c",
   "metadata": {},
   "source": [
    "### 2.2.1. Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adjacency matrix is defined as A=(a_ij), where a_ij=1 if i=j or (g_i, g_j) belongs to E and a_ij=0 if (g_i, g_j) does \n",
    "# not belong to E.\n",
    "def path_adjacency_matrix(nodes):\n",
    "    tmp_adj=[]\n",
    "    \n",
    "    #i=j -> a_ij=1\n",
    "    for i in range(len(nodes)):\n",
    "        tmp_adj.append([0]*len(nodes))\n",
    "        for j in range(len(nodes)):\n",
    "            if(i==j):\n",
    "                tmp_adj[i][j]=1\n",
    "                continue\n",
    "                \n",
    "    # (g_i,g_j) belongs to E (current sub-paths are linear) -> a_ij=1          \n",
    "    for i in range(len(nodes)-1):\n",
    "        tmp_adj[i][i+1]=1\n",
    "        tmp_adj[i+1][i]=1\n",
    "            \n",
    "    return tmp_adj\n",
    "\n",
    "# Returns the adjacency matrices of each sub-path\n",
    "def adjacency_matrix(paths):\n",
    "    adj_matrices={}\n",
    "    for path in paths:\n",
    "        adj_matrices.update({path:path_adjacency_matrix(paths[path])})\n",
    "    return adj_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03dc28",
   "metadata": {},
   "source": [
    "#### 2.2.1.2. Define PCI\n",
    "Assuming that x_is is the normalized log expression measurement for gene i in sample s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0baf937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_normalization(df):\n",
    "    # Each column expression values are normalized to zero mean.\n",
    "    tmp_df=df.copy()\n",
    "    tmp_df=(tmp_df-tmp_df.mean())/tmp_df.std()\n",
    "\n",
    "    # Further normalize to (-0.5,0.5) with Sigmoid function (Sigmoid (x_is) - 0.5) to lower the effects of extremely large/small \n",
    "    # values for gene i in sample s.\n",
    "    x={}\n",
    "    for gene in tmp_df.columns:\n",
    "        tmp_gene=[]\n",
    "        for sample in range(tmp_df.shape[0]):\n",
    "            tmp_gene.append((1 / (1 + math.exp(-df[gene].iloc[sample]))-0.5))\n",
    "        x.update({gene:tmp_gene})\n",
    "    return x\n",
    "\n",
    "#gene_expression_df=pd.DataFrame(sigmoid_normalization(gse2034_df),index=gse2034_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Define x for a specific sub-path and sample\n",
    "def sample_x(path,sample):\n",
    "    x=[]\n",
    "    for node in path:\n",
    "        cur_node=[]\n",
    "        for gene in node:\n",
    "            if(not(gene in sample.index)):\n",
    "                cur_node.append(sample['noProbe'])\n",
    "                continue\n",
    "            cur_node.append(sample[gene])\n",
    "        #Each node consists of one or more genes, so each node gets the average value.\n",
    "        x.append(mean(cur_node))\n",
    "    return x\n",
    "\n",
    "# Define x for a specific sub-path and each sample\n",
    "def get_x(path,samples):\n",
    "    x=[]\n",
    "    for sample in range(samples.shape[0]):\n",
    "        x.append(sample_x(path,samples.iloc[sample]))\n",
    "    return x\n",
    "        \n",
    "# Node_genes is initialized \n",
    "#x=get_x(node_genes[path_no],gene_expression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c086ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_PCI(path,x,a):\n",
    "    # Number of genes (ignore the edges)\n",
    "    N=len(path)\n",
    "    pci=0\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            pci+=np.sign(x[i]+x[j])*(abs(x[i])**0.5)*a[i][j]*(abs(x[j])**0.5)\n",
    "    return pci\n",
    "\n",
    "# Calculate PCI for a specific sub-path and each sample\n",
    "def PCI(path,x,a):\n",
    "    pci=[]\n",
    "    for sample in range(len(x)):\n",
    "        pci.append(path_PCI(path,x[sample],a))\n",
    "    return pci\n",
    "\n",
    "#pci=PCI(node_genes[path_no],x,path_adjacency_matrix(node_genes[path_no]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30fe3e",
   "metadata": {},
   "source": [
    "### 2.2.2. Normalize PCI (divided by the gene number in pathway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_PCI(pci,path):\n",
    "    norm_pci=[]\n",
    "    for sample in range(len(pci)):\n",
    "        cur_len=len(path)\n",
    "        norm_pci.append(pci[sample]/cur_len)\n",
    "    return norm_pci\n",
    "\n",
    "#norm_pci=normalize_PCI(pci,node_genes[path_no])\n",
    "#tappa_df=pd.DataFrame(norm_pci,columns=[path_no])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ee077",
   "metadata": {},
   "source": [
    "### 2.2.3. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50995b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def tappa_5(gene_expression_df,node_genes,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    tappa_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(selected_df.shape[0]*0.05))\n",
    "        i+=1\n",
    "        x=get_x(node_genes[path],gene_expression_df)\n",
    "        pci=PCI(node_genes[path],x,path_adjacency_matrix(node_genes[path]))\n",
    "        tappa_scores.append(normalize_PCI(pci,node_genes[path]))\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_tappa_df = pd.read_csv ('Results/TAPPA.csv')\n",
    "        prev_tappa_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_tappa_df=pd.DataFrame(np.array(tappa_scores).T, columns=new_cols)\n",
    "        tmp_tappa_df.index=gse2034_df.index\n",
    "\n",
    "        new_tappa_df=pd.concat([prev_tappa_df, tmp_tappa_df], axis=1)\n",
    "        new_tappa_df.to_csv('Results/TAPPA.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_tappa_df=pd.DataFrame(np.array(tappa_scores).T,columns=new_cols)\n",
    "        tmp_tappa_df.to_csv('Results/TAPPA.csv',index=False)\n",
    "    print('---------------')\n",
    "   \n",
    "'''\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "gene_expression_df=pd.DataFrame(sigmoid_normalization(gse2034_df),index=gse2034_df.index)\n",
    "for t in range(times+1):\n",
    "    tappa_5(gene_expression_df,node_genes,t)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tappa_df = pd.read_csv ('Results/TAPPA.csv')\n",
    "tappa_df.index=gse2034_df.index\n",
    "tappa_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4fa0f",
   "metadata": {},
   "source": [
    "## 2.3. GraphiteWeb- Enrichment analysis (competitive and non-topological)\n",
    "### 2.3.1. Probability P\n",
    "#### 2.3.1.1. Hypergeometric Distribution\n",
    "https://towardsdatascience.com/hypergeometric-distribution-explained-with-python-2c80bc613bf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "\n",
    "def hypergeom_pmf(N, A, n, x):\n",
    "    \n",
    "    '''\n",
    "    Probability Mass Function for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param x: number of desired items in our draw of n items\n",
    "    :returns: PMF computed at x\n",
    "    '''\n",
    "    Achoosex = math.comb(A,x)\n",
    "    NAchoosenx = math.comb(N-A, n-x)\n",
    "    Nchoosen = math.comb(N,n)\n",
    "    \n",
    "    return (Achoosex)*NAchoosenx/Nchoosen\n",
    "\n",
    "def hypergeom_cdf(N, A, n, t, min_value=None):\n",
    "    \n",
    "    '''\n",
    "    Cumulative Density Funtion for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param t: number of desired items in our draw of n items up to t\n",
    "    :returns: CDF computed up to t\n",
    "    '''\n",
    "    if min_value:\n",
    "        return np.sum([hypergeom_pmf(N, A, n, x) for x in range(min_value, t+1)])\n",
    "    \n",
    "    return np.sum([hypergeom_pmf(N, A, n, x) for x in range(t+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d03152",
   "metadata": {},
   "source": [
    "#### 2.3.1.2. Expression value of each gene and DEGs in every subpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ed232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_genes_expr_values(path,sample):\n",
    "    expr_vals=[]\n",
    "    for node in range(len(path)):\n",
    "        cur_n=[]\n",
    "        for g in path[node]:\n",
    "            if(not g in sample.index):\n",
    "                g='noProbe'\n",
    "            cur_n.append(sample[g])\n",
    "        expr_vals.append(cur_n)\n",
    "    return expr_vals\n",
    "\n",
    "def genes_expr_values(path,samples):\n",
    "    expr_vals=[]\n",
    "    for sample in range(samples.shape[0]):\n",
    "        expr_vals.append(sample_genes_expr_values(path,samples.iloc[sample]))\n",
    "    return expr_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3673ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of DEGs in specific sub-path and sample\n",
    "def sample_DEGs(path,z,threshold):\n",
    "    degs=0\n",
    "    for node in path:\n",
    "        node_NEGs,node_NDEGs=node_status(node,z,threshold)\n",
    "        degs+=node_NDEGs\n",
    "    return degs\n",
    "\n",
    "# Number of DEGs in specific sub-path and each sample\n",
    "def DEGs(path,z,threshold):\n",
    "    degs=[]\n",
    "    for sample in range(z.shape[0]):\n",
    "        degs.append(sample_DEGs(path,z.iloc[sample],threshold))\n",
    "    return degs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1524b",
   "metadata": {},
   "source": [
    "#### 2.3.1.3. Calculate probability P\n",
    "Two-way contigency table\n",
    "DEG: differentially expressed genes\n",
    "EEG: equally expressed genes (mean expression levels are the same across all replicates in two comparison groups)\n",
    "N: total number of genes screened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P for a specific sub-path and sample\n",
    "def sample_P(path,z,threshold,N,N_deg,N_eeg):\n",
    "    expr_val=[]\n",
    "    \n",
    "    # Total\n",
    "    N_G=len(list(chain.from_iterable(path))) # Total number of genes in current subpath G\n",
    "    N_CG=N-N_G # Total number of genes in the complement of G\n",
    "    \n",
    "    # DEG\n",
    "    n_G_deg=sample_DEGs(path,z,threshold) # Number of DEGs in subpath\n",
    "    n_CG_deg=N_deg-n_G_deg # Number of DEGs in the complement of G\n",
    "    \n",
    "    p = sum([hypergeom_cdf(N,N_deg,N_G,x,n_G_deg) for x in range(N_G+1)]) # N_G_deg>=n_G_deg\n",
    "    return p\n",
    "\n",
    "def P(path,z,threshold,N,N_deg,N_eeg):\n",
    "    p=[]\n",
    "    for sample in range(z.shape[0]):\n",
    "        p.append(sample_P(path,z.iloc[sample],threshold,N,N_deg,N_eeg))\n",
    "    return p\n",
    "\n",
    "#N=gse2034_df.shape[1] # Total number of genes screened \n",
    "#N_deg=gse2034_df2['P-Value'][gse2034_df2['P-Value']<=pvalue_threshold].shape[0] # Total number of DEGs\n",
    "#N_eeg= N-N_deg # The genes that are not differentially expressed\n",
    "\n",
    "#p=P(node_genes[path_no],z_score_df,z_threshold,N,N_deg,N_eeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb005e",
   "metadata": {},
   "source": [
    "### 2.3.2. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each node is assigned a value derived from expression data. The following values are assigned to the node: 0 if the \n",
    "# corresponding gene or genes are not expressed (z-score < 0), 1 if they are expressed but remain unchanged (z-score > 0 \n",
    "# and z-score < threshold), or the maximum fold-change value if one or more of the mapped transcripts is above threshold\n",
    "# (z-score > threshold).\n",
    "\n",
    "def gene_status(z,threshold):\n",
    "    if(z<0):\n",
    "        return \"not expressed\"\n",
    "    # Expressed (z-score > 0)\n",
    "    if(z<threshold): # non-significant\n",
    "        return \"non-significant\"\n",
    "    else: # significant\n",
    "        return \"significant\"\n",
    "\n",
    "# Return the number of expressed genes and significant genes for a node in a specific sub-path with a specific sample's data\n",
    "def node_status(node,z,threshold):\n",
    "    status=[]\n",
    "    for gene in node:\n",
    "        if(not gene in z.index):\n",
    "            node_status.append(gene_status(z['noProbe'],threshold))\n",
    "            continue\n",
    "        status.append(gene_status(z[gene],threshold))\n",
    "    NDEGs=status.count('significant')\n",
    "    NEGs=NDEGs+status.count('non-significant')\n",
    "    return NEGs,NDEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def graphiteweb_5(node_genes,z_score_df,z_threshold,N,N_deg,N_eeg,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    graphiteweb_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(len(node_genes)*0.05))\n",
    "        i+=1\n",
    "        \n",
    "        p=P(node_genes[path],z_score_df,z_threshold,N,N_deg,N_eeg)\n",
    "        graphiteweb_scores.append(p)\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_graphiteweb_df = pd.read_csv ('Results/GraphiteWeb.csv')\n",
    "        prev_graphiteweb_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_graphiteweb_df=pd.DataFrame(np.array(graphiteweb_scores).T, columns=new_cols)\n",
    "        tmp_graphiteweb_df.index=gse2034_df.index\n",
    "\n",
    "        new_graphiteweb_df=pd.concat([prev_graphiteweb_df, tmp_graphiteweb_df], axis=1)\n",
    "        new_graphiteweb_df.to_csv('Results/GraphiteWeb.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_graphiteweb_df=pd.DataFrame(np.array(graphiteweb_scores).T,columns=new_cols)\n",
    "        tmp_graphiteweb_df.to_csv('Results/GraphiteWeb.csv',index=False)\n",
    "    print('---------------')\n",
    "\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "\n",
    "N=gse2034_df.shape[1] # Total number of genes screened \n",
    "N_deg=gse2034_df2['P-Value'][gse2034_df2['P-Value']<=pvalue_threshold].shape[0] # Total number of DEGs\n",
    "N_eeg= N-N_deg # The genes that are not differentially expressed\n",
    "#for t in range(times+1):\n",
    "#    graphiteweb_5(node_genes,z_score_df,z_threshold,N,N_deg,N_eeg,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphiteweb_df = pd.read_csv ('Results/GraphiteWeb.csv')\n",
    "#graphiteweb_df.index=gse2034_df.index\n",
    "#graphiteweb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131185ee",
   "metadata": {},
   "source": [
    "## 2.4. TEAK\n",
    "### 2.4.1. SubPathway Ranking\n",
    "#### 2.4.1.1. Conditional Probability Distribution\n",
    "- Node Y with m continuous parents X1,...,Xm\n",
    "- β0, ... , βm are the regression coefficients\n",
    "- σ^2 is the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6be88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression coefficients (b1=Σ[(xi-x)(yi-y)]/Σ[(xi-x)], where x and y are the mean values of x and y respectively)\n",
    "# Since our subpaths are linear, each node Y has one parent node x, and so only 2 coefficients (β0,β1).\n",
    "def estimate_coef(x, y):\n",
    "    # number of observations/points\n",
    "    n = np.size(x)\n",
    "  \n",
    "    # mean of x and y vector\n",
    "    m_x = np.mean(x)\n",
    "    m_y = np.mean(y)\n",
    "    \n",
    "    if(n==1):\n",
    "        # calculating cross-deviation and deviation about x\n",
    "        SS_xy = (y*x)[0]\n",
    "        SS_xx = (x*x)[0]\n",
    "    else:\n",
    "        # calculating cross-deviation and deviation about x\n",
    "        SS_xy = sum(y*x) - n*m_y*m_x\n",
    "        SS_xx = sum(x*x) - n*m_x*m_x\n",
    "    \n",
    "    # calculating regression coefficients\n",
    "    if(SS_xx): # If SS_xx is not zero the proceed with the division\n",
    "        b_1 = SS_xy / SS_xx\n",
    "    else: \n",
    "        b_1=0\n",
    "    b_0 = m_y - b_1*m_x\n",
    "  \n",
    "    return (b_0, b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import scipy.stats\n",
    "\n",
    "# Calculate the Conditional Probability Distribution for a specific node and sub-path\n",
    "def node_cond_prob_distr(node_no,expr_vals,reg_coef,variance):\n",
    "    distr_mean=reg_coef[0]\n",
    "    if(node_no==0): # If current node is root (without parents), then return β0\n",
    "        return distr_mean\n",
    "    distr_mean+=reg_coef[1]*expr_vals[node_no-1]\n",
    "    \n",
    "    distribution = scipy.stats.norm(loc=distr_mean,scale=variance)\n",
    "    sample = distribution.rvs(size=1)[0] # linear networks: size=1\n",
    "\n",
    "    return sample\n",
    "    \n",
    "# Calculate the Conditonal Probability Distribution for a specific sample and sub-path\n",
    "def sample_cond_prob_distr(expr_vals):\n",
    "    x = np.array(expr_vals[:-1]) # Continuous parents x1,...,xm\n",
    "    y = np.array(expr_vals[1:]) # Continuous nodes Y\n",
    "    reg_coef=estimate_coef(y,x)\n",
    "\n",
    "    if(len(y)>1):\n",
    "        variance=statistics.variance(y)\n",
    "    else:\n",
    "        variance=y[0]\n",
    "\n",
    "    cond_prob=[]\n",
    "    for node in range(len(expr_vals)):\n",
    "        cond_prob.append(node_cond_prob_distr(node,expr_vals,reg_coef,variance))\n",
    "    return cond_prob\n",
    "    \n",
    "# Calculate the Conditional Probability Distribution for a specific sub-path and each sample\n",
    "def cond_prob_distr(expr_vals):\n",
    "    cond_prob=[]\n",
    "    for sample in range(len(expr_vals)):\n",
    "        cond_prob.append(sample_cond_prob_distr(expr_vals[sample]))\n",
    "    return cond_prob\n",
    "\n",
    "#cond_prob=cond_prob_distr(subpath_expression_value(node_genes[path_no],gse2034_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e9e9d",
   "metadata": {},
   "source": [
    "#### 2.4.1.2.  Score_BIC=logP(D|θ)-0.5d*logN\n",
    "- D: gene expression data\n",
    "- θ: maximum likelihood estimate of the parameters used to represent the linear Gaussian node\n",
    "- d: number of parameters\n",
    "- N: number of samples in the gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7703987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node's BIC score for a specific sub-path and sample\n",
    "def node_score_BIC(cond_prob_distr,node_no,N):\n",
    "    if(node_no==0):\n",
    "        return math.log(cond_prob_distr[node_no]+1-min(cond_prob_distr)) # Only 1 parent node\n",
    "    # Else: All other nodes have only 1 parent node (d=1)\n",
    "    # Logarithm of negative values: Translate, then Transform (log(Y + 1 - min(Y)))\n",
    "    # Source: https://blogs.sas.com/content/iml/2011/04/27/log-transformations-how-to-handle-negative-data-values.html\n",
    "    score=math.log(cond_prob_distr[node_no]+1-min(cond_prob_distr))-0.5*math.log(N)\n",
    "    return score\n",
    "\n",
    "# Get BIC score for a specific sub-path and sample\n",
    "def sample_score_BIC(cond_prob_distr,N):\n",
    "    score=[]\n",
    "    for node in range(len(cond_prob_distr)):\n",
    "        score.append(node_score_BIC(cond_prob_distr,node,N))\n",
    "        \n",
    "    # Sum all nodes' scores and return final result\n",
    "    return sum(score)\n",
    "\n",
    "# Get BIC score for a specific sub-path and each sample\n",
    "def score_BIC(cond_prob,N):\n",
    "    score=[]\n",
    "    for sample in range(len(cond_prob)):\n",
    "        score.append(sample_score_BIC(cond_prob[sample],N))\n",
    "    return score\n",
    "    \n",
    "#bic=score_BIC(cond_prob,gse2034_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1707dd9",
   "metadata": {},
   "source": [
    "#### 2.4.1.3. Normalize scores\n",
    "The score for each subpathway is normalized by its number of nodes, so that the scores are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccee0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_scores(scores,path):\n",
    "    normalized_scores=[]\n",
    "    for sample in range(len(scores)):\n",
    "        normalized_scores.append(scores[sample]/len(path))\n",
    "    return normalized_scores\n",
    "\n",
    "#norm_score_BIC=get_normalized_scores(bic,node_genes[path_no])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02243a0b",
   "metadata": {},
   "source": [
    "### 2.4.2. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e79acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def teak_5(node_genes,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    teak_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(len(node_genes)*0.05))\n",
    "        i+=1\n",
    "        \n",
    "        cond_prob=cond_prob_distr(subpath_expression_value(node_genes[path],gse2034_df))\n",
    "        bic=score_BIC(cond_prob,gse2034_df.shape[1])\n",
    "        norm_score_BIC=get_normalized_scores(bic,node_genes[path])\n",
    "        teak_scores.append(norm_score_BIC)\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_teak_df = pd.read_csv ('Results/TEAK.csv')\n",
    "        prev_teak_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_teak_df=pd.DataFrame(np.array(teak_scores).T, columns=new_cols)\n",
    "        tmp_teak_df.index=gse2034_df.index\n",
    "\n",
    "        new_teak_df=pd.concat([prev_teak_df, tmp_teak_df], axis=1)\n",
    "        new_teak_df.to_csv('Results/TEAK.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_teak_df=pd.DataFrame(np.array(teak_scores).T,columns=new_cols)\n",
    "        tmp_teak_df.to_csv('Results/TEAK.csv',index=False)\n",
    "    print('---------------')\n",
    "\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "\n",
    "#for t in range(times+1):\n",
    "#    teak_5(node_genes,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aad0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teak_df = pd.read_csv ('Results/TEAK.csv')\n",
    "#teak_df.index=gse2034_df.index\n",
    "#teak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14adb9",
   "metadata": {},
   "source": [
    "## 2.5. DEAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfce130",
   "metadata": {},
   "source": [
    "### 2.5.1. Expression data\n",
    "- Formula: E=d(μ+g)+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indicator of whether a gene is ‘on’ or ‘off’\n",
    "def get_d(pvalues,fc):\n",
    "    d=[]\n",
    "    on_genes=[]\n",
    "    for p in range(len(pvalues)):\n",
    "        # fold change > 0 indicates up-regulation and fold change < 0 indicates down-regulation of genes\n",
    "        # pvalue <= 0.05 indicates that the gene is on, else gene is off\n",
    "        if(pvalues[p]>pvalue_threshold): # Gene is off\n",
    "            d.append(0)\n",
    "        else: # Gene is on\n",
    "            on_genes.append(fc[p])\n",
    "            if(fc[p]>0): # up-regulated\n",
    "                d.append(1)\n",
    "            else: # down-regulated\n",
    "                d.append(-1)\n",
    "    return d\n",
    "\n",
    "#get_d(pvalues,fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ac192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of the absolute value of expression for ‘on’ genes (pathway effect) of a specific sub-path and sample\n",
    "def get_m(pvalues,pvalue_threshold,expr_vals,samples):\n",
    "    m=[]\n",
    "    for node in range(len(expr_vals)):\n",
    "        if(pvalues[node]<=pvalue_threshold): # If the gene is turned on\n",
    "            m.append(abs(expr_vals[node])) # Get the absolute expression value of the node\n",
    "    if(len(m)):\n",
    "        return statistics.mean(m)\n",
    "    return 0 # If there are no on genes\n",
    "\n",
    "#get_m(pvalues,pvalue_threshold,subpath_expr_val[0],gse2034_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1753ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance of individual gene for a specific sub-path and sample\n",
    "def variance(data): # σ\n",
    "    # Number of observations\n",
    "    n = len(data)\n",
    "    # Mean of the data\n",
    "    mean = sum(data) / n\n",
    "    # Square deviations\n",
    "    deviations = [(x - mean) ** 2 for x in data]\n",
    "    # Variance\n",
    "    variance = sum(deviations) / n\n",
    "    return variance\n",
    "\n",
    "# Normal distribution of specific sub-path, sample and node\n",
    "def normal_dist(x , mean , sd):\n",
    "    prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return prob_density\n",
    "\n",
    "# The variable g for a specific sub-path and sample is assumed to come from a normal distribution with mean 0 and variance σ\n",
    "def sample_g(expr_val):\n",
    "    mean=0\n",
    "    s=variance(expr_val)\n",
    "    if(s==0): # If the variance equals to zero, then the variable g is also zero, since division by zero is not possible. \n",
    "        g=len(expr_val)*[0]\n",
    "    else:\n",
    "        g=[]\n",
    "        for node in range(len(expr_val)):\n",
    "            g.append(normal_dist(expr_val[node],mean,s))\n",
    "    return g\n",
    "\n",
    "def get_g(samples_expr_val):\n",
    "    g=[]\n",
    "    for sample in range(len(samples_expr_val)):\n",
    "        g.append(sample_g(samples_expr_val[sample]))\n",
    "    return g\n",
    "\n",
    "#sample_g(subpath_expr_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate e for a specific sub-path and sample\n",
    "def sample_e(expr_val):\n",
    "    mean=0\n",
    "    s=1\n",
    "    e=[]\n",
    "    for node in range(len(expr_val)):\n",
    "        e.append(normal_dist(expr_val[node],mean,s))\n",
    "    return e\n",
    "\n",
    "# Calculate e for a specific sub-path and each sample\n",
    "def get_e(samples_expr_val):\n",
    "    e=[]\n",
    "    for sample in range(len(samples_expr_val)):\n",
    "        e.append(sample_e(samples_expr_val[sample]))\n",
    "    return e\n",
    "\n",
    "#get_e(subpath_expr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1958d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression data (presumably on a log scale) for each gene in a pathway was simulated using a multivariate normal distribution\n",
    "def sample_E(expr_val,d,m):\n",
    "    g=sample_g(expr_val)\n",
    "    e=sample_e(expr_val)\n",
    "    \n",
    "    node_E=[]\n",
    "    for node in range(len(expr_val)):\n",
    "        node_E.append(d[node]*(m+g[node])+e[node])\n",
    "    return node_E\n",
    "        \n",
    "# E for a specific sub-path and each sample\n",
    "def E(samples_expr_val,pvalues,pvalue_threshold,fc,genes):\n",
    "    E=[]\n",
    "    for sample in range(len(samples_expr_val)):\n",
    "        d=get_d(pvalues,fc)\n",
    "        m=get_m(pvalues,pvalue_threshold,samples_expr_val[sample],genes)\n",
    "        E.append(sample_E(samples_expr_val[sample],d,m))\n",
    "    return E\n",
    "\n",
    "#E(subpath_expr_val,pvalues,pvalue_threshold,fc,gse2034_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b83d5e",
   "metadata": {},
   "source": [
    "### 2.5.2. Calculate differential expression\n",
    "- A recursive function calculates the differential expression for each path by adding or subtracting all downstream nodes with catalytic or inhibitory relationships, respectively.\n",
    "- The absolute value of the expression level is utilized as the DEAP score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1+(B2*relation+(B3*relation+(...)))\n",
    "def sample_deap_score(expr_val,edges,relations_dict,path=[]):\n",
    "    if(len(path)>0): # Check if there is a specific subpath provided\n",
    "        expr_val=path\n",
    "        \n",
    "    score=expr_val[-1]\n",
    "    for node in range(len(expr_val)-2,-1,-1): # Recursive: start from the final node\n",
    "        e=len(edges)-(len(expr_val)-node-1)\n",
    "        if(edges[e]==relations_dict['Activation']): # Activation: +1\n",
    "            score+=(expr_val[node]*1)\n",
    "        else: # Inhibition: -1\n",
    "            score+=(expr_val[node]*-1)\n",
    "    # Return the absolute value of the score\n",
    "    return abs(score)\n",
    "\n",
    "def deap_score(samples_expr_val,edges,relations_dict):\n",
    "    deap_score=[]\n",
    "    for sample in range(len(samples_expr_val)):\n",
    "        deap_score.append(sample_deap_score(samples_expr_val[sample],edges,relations_dict))\n",
    "    return deap_score\n",
    "\n",
    "#path=list(selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()])\n",
    "#edges=list(path[1::2])\n",
    "#subpath_expr_val=subpath_expression_value(node_genes[path_no],gse2034_df)\n",
    "#score=deap_score(subpath_expr_val,edges,relations_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74211a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath_expression_value(node_genes[path_no],gse2034_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144e15b",
   "metadata": {},
   "source": [
    "### 2.5.3. Random rotation\n",
    "- Rotate data n times and recalculate DEAP score for every rotation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateList(arr,d=1):\n",
    "    n=len(arr)\n",
    "    arr[:]=arr[d:n]+arr[0:d]\n",
    "    return arr\n",
    "\n",
    "# Rotate specific sub-path with specific sample's expression values\n",
    "def sample_random_rotation(expr_val,edges,relations_dict,score_list=[],k=0,n=100):\n",
    "    score_list.append(sample_deap_score(expr_val,edges,relations_dict))\n",
    "    \n",
    "    if(k==n):\n",
    "        return score_list\n",
    "        \n",
    "    tmp_expr_val=list.copy(expr_val)\n",
    "    rotated_expr_val=rotateList(tmp_expr_val)\n",
    "    rotated_score=sample_deap_score(rotated_expr_val,edges,relations_dict)\n",
    "    \n",
    "    return sample_random_rotation(rotated_expr_val,edges,relations_dict,score_list,k+1)\n",
    "\n",
    "# Rotate specific sub-path for eahc sample\n",
    "def random_rotation(samples_expr_val,edges,relations_dict):\n",
    "    new_score=[]\n",
    "    for sample in range(len(samples_expr_val)):\n",
    "        new_score.append(statistics.mean(sample_random_rotation(samples_expr_val[sample],edges,relations_dict)))\n",
    "    return new_score\n",
    "\n",
    "#rotated_score=random_rotation(subpath_expr_val,edges,relations_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7268ad",
   "metadata": {},
   "source": [
    "### 2.5.4. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b629769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def deap_5(node_genes,relations_dict,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    deap_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(len(node_genes)*0.05))\n",
    "        i+=1\n",
    "        \n",
    "        cur_path=list(selected_df.iloc[path][~selected_df.iloc[path].isnull()])\n",
    "        edges=list(cur_path[1::2])\n",
    "        subpath_expr_val=subpath_expression_value(node_genes[path],gse2034_df)\n",
    "        rotated_score=random_rotation(subpath_expr_val,edges,relations_dict)\n",
    "        deap_scores.append(rotated_score)\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_deap_df = pd.read_csv ('Results/DEAP.csv')\n",
    "        prev_deap_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_deap_df=pd.DataFrame(np.array(deap_scores).T, columns=new_cols)\n",
    "        tmp_deap_df.index=gse2034_df.index\n",
    "\n",
    "        new_deap_df=pd.concat([prev_deap_df, tmp_deap_df], axis=1)\n",
    "        new_deap_df.to_csv('Results/DEAP.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_deap_df=pd.DataFrame(np.array(deap_scores).T,columns=new_cols)\n",
    "        tmp_deap_df.to_csv('Results/DEAP.csv',index=False)\n",
    "    print('---------------')\n",
    "\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "\n",
    "#for t in range(times+1):\n",
    "#    deap_5(node_genes,relations_dict,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deap_df = pd.read_csv ('Results/DEAP.csv')\n",
    "#deap_df.index=gse2034_df.index\n",
    "#deap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec439bc",
   "metadata": {},
   "source": [
    "## 2.6. PRS\n",
    "Each node in a pathway has three attributes: Node_genes, Node_value (NV), Node_weight (NW)\n",
    "### 2.6.1.  Development of the PRS algorithm\n",
    "#### 2.6.1.1. Node_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already calculated on 1.3.1.\n",
    "node_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef869f46",
   "metadata": {},
   "source": [
    "#### 2.6.1.2. Node_value (NV)\n",
    "Instead of p-value, the z-score was computed for each gene and sample, in order to categorize them as non-expressed, expressed but non-significant and expressed and significant (above threshold). The value selected for z-score threshold is 1.96 (corresponding to p-value's threshold=0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific sub-path and sample assign to each node consisting of one or more genes the corresponding z-values\n",
    "def Sample_Z_Score(path,sample_z_score):\n",
    "    z_score=[]\n",
    "    for node in path:\n",
    "        z_node=[]\n",
    "        for gene in node:\n",
    "            if(not gene in sample_z_score.index):\n",
    "                z_node.append(sample_z_score['noProbe'])\n",
    "                continue\n",
    "            z_node.append(sample_z_score[gene])\n",
    "        z_score.append(z_node)\n",
    "    return z_score\n",
    "\n",
    "# For a specific sub-path and each sample assign the corresponding z-score values\n",
    "def Z_Score(path,sample_z):\n",
    "    z=[]\n",
    "    for sample in range(sample_z.shape[0]):\n",
    "        z.append(Sample_Z_Score(path,sample_z.iloc[sample]))\n",
    "    return z\n",
    "\n",
    "z_score=Z_Score(node_genes[path_no],z_score_df)\n",
    "z_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific sub-path and sample calculate the Node_Value.\n",
    "def sample_Node_Value(path,sample,z,threshold,fc):\n",
    "    node_value=[]\n",
    "    for node in path:\n",
    "        status={}\n",
    "        node_fc=[]\n",
    "        for gene in node:\n",
    "            if(not gene in sample.index):\n",
    "                status.update({gene:gene_status(z['noProbe'],threshold)})\n",
    "                node_fc.append(fc['noProbe'])\n",
    "                continue\n",
    "            status.update({gene:gene_status(z[gene],threshold)})\n",
    "            node_fc.append(fc[gene])\n",
    "            \n",
    "        # If one or more genes are significant assign the maximum fold-change value as node_value\n",
    "        if(list(status.values()).count('significant')):\n",
    "            node_value.append(max(node_fc))\n",
    "        else:\n",
    "            tmp_value=[]\n",
    "            for gene in status:\n",
    "                if(status[gene]=='non-significant'): # 1 (significant)\n",
    "                    tmp_value.append(1)\n",
    "                else: # 0 (not expressed)\n",
    "                    tmp_value.append(0)\n",
    "            node_value.append(statistics.mean(tmp_value)) # Get average\n",
    "    return node_value\n",
    " \n",
    "# For a specific sub-path and each sample calculate the Node_Value\n",
    "def Node_Value(path,samples,z,threshold,fc):\n",
    "    node_value=[]\n",
    "    for sample in range(samples.shape[0]):\n",
    "        node_value.append(sample_Node_Value(path,samples.iloc[sample],z.iloc[sample],z_threshold,fc))\n",
    "    return node_value\n",
    "\n",
    "#NV=Node_Value(node_genes[path_no],gse2034_df,z_score_df,z_threshold,gse2034_df2['Fold Change'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbb4cd",
   "metadata": {},
   "source": [
    "#### 2.6.1.3. Node_weight (NW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb01f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All significant (above-threshold) nodes were assigned a weighting that reflected\n",
    "# their topological strength (i.e., the number of significant downstream nodes that are pointed to, either\n",
    "# directly or via other significant nodes).\n",
    "# An initiating child node, n_i, was ignored if non-significant, and the algorithm proceeds to the next child.\n",
    "# Otherwise, we increase the weight counter by 1 and look for children of this node\n",
    "# and so on. All non-significant nodes have NW = 0.\n",
    "\n",
    "# Returns the number of significant children a node has for a specific sub-path and sample    \n",
    "def significant_children(nodes,z,threshold,weight=0):\n",
    "    if(len(nodes)==0): # Reached the end\n",
    "        return weight\n",
    "    \n",
    "    status=[]\n",
    "    for gene in nodes[0]:\n",
    "        if(gene not in z.index):\n",
    "            status.append(gene_status(z['noProbe'],threshold))\n",
    "            continue\n",
    "        status.append(gene_status(z[gene],threshold))\n",
    "\n",
    "    if(status.count('significant')): # Significant\n",
    "        return significant_children(nodes[1:],z,threshold,weight+1)\n",
    "    else:\n",
    "        return significant_children(nodes[1:],z,threshold,weight)\n",
    "\n",
    "def sample_Node_Weight(path,z,threshold):\n",
    "    node_weight=[]\n",
    "    for node in range(len(path)):\n",
    "        node_weight.append(significant_children(path[node:],z,threshold))\n",
    "    return node_weight\n",
    "\n",
    "def Node_Weight(path,z_samples,threshold):\n",
    "    node_weight=[]\n",
    "    for sample in range(z_samples.shape[0]):\n",
    "        node_weight.append(sample_Node_Weight(path,z_samples.iloc[sample],threshold))\n",
    "    return node_weight\n",
    "\n",
    "#NW=Node_Weight(node_genes[path_no],z_score_df,z_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb2fdf",
   "metadata": {},
   "source": [
    "#### 2.6.1.4. Node_score (NS)\n",
    "NV and NW values are combined to calculate a Node_Score (NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229179cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Node_Score(NV,NW):\n",
    "    node_score=[]\n",
    "    for node in range(len(NV)):\n",
    "        if(NV[node]>1):\n",
    "            node_score.append(NV[node]*NW[node])\n",
    "        else:\n",
    "            node_score.append(0)\n",
    "    return node_score\n",
    "\n",
    "def Node_Score(NV,NW):\n",
    "    node_score=[]\n",
    "    for sample in range(len(NV)):\n",
    "        node_score.append(sample_Node_Score(NV[sample],NW[sample]))\n",
    "    return node_score\n",
    "\n",
    "#NS=Node_Score(NV,NW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607a9d7",
   "metadata": {},
   "source": [
    "#### 2.6.1.5. PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRS(NS):\n",
    "    prs=[]\n",
    "    for sample in range(len(NS)):\n",
    "        prs.append(sum(NS[sample]))\n",
    "    return prs\n",
    "\n",
    "#prs=PRS(NS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd2ef0",
   "metadata": {},
   "source": [
    "### 2.6.2. Normalizing pathway scores\n",
    "A normalization step is required to control for two key features: \n",
    "- pathway size \n",
    "- statistical bias contributed by pathway-specific PRS score null distributions.\n",
    "\n",
    "#### 2.6.2.1.  Pathway size \n",
    "Multiply each PRS score by the ratio of the number of DEGs (NDEGs) in a pathway to the total number of expressed genes (NEGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of expressed genes and significant genes for each node in a specific sub-path with a specific sample's data\n",
    "def sample_NEG_NDEG(path,z,threshold):\n",
    "    NEGs=0\n",
    "    NDEGs=0\n",
    "    for node in path:\n",
    "        node_NEGs,node_NDEGs=node_status(node,z,threshold)\n",
    "        NEGs+=node_NEGs\n",
    "        NDEGs+=node_NDEGs\n",
    "    return NEGs,NDEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a specific pathway to control their pathway size for a specific sample\n",
    "def sample_Path_Size_Normalization(path,prs,z,threshold):\n",
    "    NEGs,NDEGs=sample_NEG_NDEG(path,z,threshold)\n",
    "    \n",
    "    # Handle division by zero\n",
    "    if(NEGs==0):\n",
    "        return 0.0\n",
    "    return prs*(NDEGs/NEGs)\n",
    "\n",
    "# Normalize a specific pathway to control their pathway size for each sample\n",
    "def Path_Size_Normalization(path,prs,z,threshold):\n",
    "    norm_prs=[]\n",
    "    for sample in range(len(prs)):\n",
    "        norm_prs.append(sample_Path_Size_Normalization(path,prs[sample],z.iloc[sample],threshold))\n",
    "    return norm_prs\n",
    "\n",
    "#normalized_prs=Path_Size_Normalization(node_genes[path_no],prs,z_score_df,z_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abaf600",
   "metadata": {},
   "source": [
    "#### 2.6.2.2. Statistical bias contributed by pathway-specific PRS score null distributions\n",
    "Computational time problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e611f",
   "metadata": {},
   "source": [
    "### 2.6.3. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def prs_5(node_genes,z_score_df,z_threshold,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    prs_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(len(node_genes)*0.05))\n",
    "        i+=1\n",
    "        \n",
    "        NV=Node_Value(node_genes[path],gse2034_df,z_score_df,z_threshold,gse2034_df2['Fold Change'])\n",
    "        NW=Node_Weight(node_genes[path],z_score_df,z_threshold)\n",
    "        NS=Node_Score(NV,NW)\n",
    "        prs=PRS(NS)\n",
    "        normalized_prs=Path_Size_Normalization(node_genes[path],prs,z_score_df,z_threshold)\n",
    "        prs_scores.append(normalized_prs)\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_prs_df = pd.read_csv ('Results/PRS.csv')\n",
    "        prev_prs_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_prs_df=pd.DataFrame(np.array(prs_scores).T, columns=new_cols)\n",
    "        tmp_prs_df.index=gse2034_df.index\n",
    "\n",
    "        new_prs_df=pd.concat([prev_prs_df, tmp_prs_df], axis=1)\n",
    "        new_prs_df.to_csv('Results/PRS.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_prs_df=pd.DataFrame(np.array(prs_scores).T,columns=new_cols)\n",
    "        tmp_prs_df.to_csv('Results/PRS.csv',index=False)\n",
    "    print('---------------')\n",
    "\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "\n",
    "#for t in range(times+1):\n",
    "#    prs_5(node_genes,z_score_df,z_threshold,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411cc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prs_df = pd.read_csv ('Results/PRS.csv')\n",
    "#prs_df.index=gse2034_df.index\n",
    "#prs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17935c8",
   "metadata": {},
   "source": [
    "## 2.7. HiPathia\n",
    "### 2.7.1. Normalize the gene expression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_gse2034_df=normalized_df=(gse2034_df-gse2034_df.min())/(gse2034_df.max()-gse2034_df.min())\n",
    "norm_gse2034_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfd61b",
   "metadata": {},
   "source": [
    "### 2.7.2. The Hipathia mechanistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95834b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized gene expression values for a specific sub-path and sample\n",
    "def sample_U(path,sample_expression):\n",
    "    u=[]\n",
    "    for node in path:\n",
    "        node_u=[]\n",
    "        for gene in node:\n",
    "            if(not gene in sample_expression.index):\n",
    "                node_u.append(sample_expression['noProbe'])\n",
    "                continue\n",
    "            node_u.append(sample_expression[gene])\n",
    "        u.append(node_u)\n",
    "    return u\n",
    "\n",
    "# Normalized gene expression values for a specific sub-path and each sample\n",
    "def U(path,samples_expression):\n",
    "    u=[]\n",
    "    for sample in range(samples_expression.shape[0]):\n",
    "        u.append(sample_U(path,samples_expression.iloc[sample]))\n",
    "    return u\n",
    "\n",
    "u=U(node_genes[path_no],norm_gse2034_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal intensity of each node\n",
    "def sample_mechanistic_model(u,edges):\n",
    "    s=[statistics.mean(u[0])]\n",
    "    for node in range(1,len(u)):\n",
    "        s_a=1\n",
    "        s_i=1\n",
    "        for prev_node in range(node):\n",
    "            # Activation signals\n",
    "            if(edges[prev_node]==relations_dict['Activation']): \n",
    "                s_a=s_a*(1-s[prev_node])\n",
    "            # Inhibition signals\n",
    "            else:\n",
    "                s_i=s_i*(1-s[prev_node])\n",
    "        new_u=statistics.mean(u[node])*s_i*s_a\n",
    "        s.append(new_u)\n",
    "    # Changes in the activity of the nodes will be reflected (or remain unnoticed) in the last effector node\n",
    "    return s[node]\n",
    "\n",
    "def mechanistic_model(u,edges):\n",
    "    s=[]\n",
    "    for sample in range(len(u)):\n",
    "        s.append(sample_mechanistic_model(u[sample],edges))\n",
    "    return s\n",
    "\n",
    "path=list(selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()])\n",
    "edges=edges=list(path[1::2]) # Edges are at the odd columns\n",
    "s=mechanistic_model(u,edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b0784",
   "metadata": {},
   "source": [
    "### 2.7.3. Compute each sub-path's score for each sample and create the final DataFrame\n",
    "Because of the computational time, each time the score of 5% of sub-paths is computed and appended in a DataFrame. The next 5% is used etc. The first 5% of sub-paths is already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each 5% of the pathways' score computed is appended to the previously created DataFrame.\n",
    "def hipathia_5(node_genes,norm_gse2034_df,already_calculated,percentage=0.05):\n",
    "    print(already_calculated)\n",
    "    \n",
    "    start=already_calculated*int(selected_df.shape[0]*0.05)\n",
    "    end=start+int(selected_df.shape[0]*0.05)\n",
    "    \n",
    "    if(end>selected_df.shape[0]):\n",
    "        end=selected_df.shape[0]\n",
    "    \n",
    "    new_cols=list(range(start,end))\n",
    "    \n",
    "    hipathia_scores=[] # Row: sub-path, columns: samples\n",
    "    i=1\n",
    "    for path in range(start,end): # The score of 5% of all sub-paths is computed, because of the computational time\n",
    "        print(i*100/int(len(node_genes)*0.05))\n",
    "        i+=1\n",
    "        \n",
    "        u=U(node_genes[path],norm_gse2034_df)\n",
    "        cur_path=list(selected_df.iloc[path][~selected_df.iloc[path].isnull()])\n",
    "        edges=edges=list(cur_path[1::2]) # Edges are at the odd columns\n",
    "        s=mechanistic_model(u,edges)\n",
    "        hipathia_scores.append(s)\n",
    "    \n",
    "    if(already_calculated):\n",
    "        prev_hipathia_df = pd.read_csv ('Results/HiPathia.csv')\n",
    "        prev_hipathia_df.index=gse2034_df.index\n",
    "\n",
    "        tmp_hipathia_df=pd.DataFrame(np.array(hipathia_scores).T, columns=new_cols)\n",
    "        tmp_hipathia_df.index=gse2034_df.index\n",
    "\n",
    "        new_hipathia_df=pd.concat([prev_hipathia_df, tmp_hipathia_df], axis=1)\n",
    "        new_hipathia_df.to_csv('Results/HiPathia.csv',index=False) # Already computed\n",
    "    else:\n",
    "        tmp_hipathia_df=pd.DataFrame(np.array(hipathia_scores).T,columns=new_cols)\n",
    "        tmp_hipathia_df.to_csv('Results/HiPathia.csv',index=False)\n",
    "    print('---------------')\n",
    "\n",
    "percentage=0.05\n",
    "times=int(1/percentage)\n",
    "\n",
    "#for t in range(times+1):\n",
    "#    hipathia_5(node_genes,norm_gse2034_df,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prs_df = pd.read_csv ('Results/PRS.csv')\n",
    "#prs_df.index=gse2034_df.index\n",
    "#prs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6450b3",
   "metadata": {},
   "source": [
    "## 2.8. SPIA\n",
    "Two types of evidence: (i) the over-representation of DE genes in a given pathway and (ii) the abnormal perturbation of that pathway, as measured by propagating measured expression changes across the pathway topology (P_NDE,P_PERT).\n",
    "### 2.8.1. P_NDE = P(X >= N_DE | H0)\n",
    "- Captures the significance of the given pathway Pi as provided by an over-representation analysis of the number of DE genes (N_DE) observed on the pathway.\n",
    "- N_DE: number of DE genes on the pathway analyzed\n",
    "- H0: the genes that appear as DE on a given pathway are completely random (the pathway is not relevant to the condition under study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc85949",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_de={} # Number of DE genes on the pathway analyzed\n",
    "for path in de_genes_dict:\n",
    "    n_de.update({path:len([1 for n in de_genes_dict[path] if n])})\n",
    "\n",
    "# Already calculated\n",
    "def get_p_nde(node_value,n_de):\n",
    "    p_nde={}\n",
    "    for path in node_value:\n",
    "        # Calculating Probability of a Random Variable in a Distribution\n",
    "        p_nde.update({path:0.5 * (1 + math.erf((n_de[path] - mean(n_de.values()))/math.sqrt(2 * stdev(n_de.values()) **2)))})\n",
    "        # p_nde.update({path:n_de[path]/len(node_value[path])})\n",
    "    return p_nde\n",
    "\n",
    "# Number of DE genes on a specific pathway analyzed for a specific sample\n",
    "def sample_DEGs(path,z,threshold):\n",
    "    degs=0\n",
    "    for node in path:\n",
    "        for gene in node:\n",
    "            if(not gene in z.index):\n",
    "                gene='noProbe'\n",
    "            if(gene_status(z[gene],threshold)=='significant'):\n",
    "                degs+=1\n",
    "    return degs\n",
    "\n",
    "def DEGs(path,z,threshold):\n",
    "    degs=[]\n",
    "    for sample in range(z.shape[0]):\n",
    "        degs.append(sample_DEGs(path,z.iloc[sample],threshold))\n",
    "    return degs\n",
    "\n",
    "def P_NDE(path,z,threshold):\n",
    "    n_de=DEGs(path,z,threshold)\n",
    "    p_nde=[]\n",
    "    \n",
    "    for sample in range(z.shape[0]):\n",
    "        # Calculating Probability of a Random Variable in a Distribution\n",
    "        p_nde.append(0.5 * (1 + math.erf((n_de[sample] - mean(n_de))/math.sqrt(2 * statistics.stdev(n_de) **2))))\n",
    "    return p_nde\n",
    "    \n",
    "p_nde=P_NDE(node_genes[path_no],z_score_df,z_threshold)\n",
    "p_nde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1664d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N=gse2034_df.shape[1]\n",
    "A=gse2034_df2[gse2034_df2['P-Value']<=pvalue_threshold].shape[0]\n",
    "n=len(sorted(set(list(chain.from_iterable(node_genes[path_no]))))) \n",
    "\n",
    "t=0 # Max number of DE genes we want (X>=Nde)\n",
    "for node in node_genes[path_no]:\n",
    "    for gene in node:\n",
    "        if(not gene in gse2034_df2.index):\n",
    "            gene='noProbe'\n",
    "        if(gse2034_df2.loc[gene]['P-Value']<=pvalue_threshold):\n",
    "            t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb\n",
    "\n",
    "def hypergeom_pmf(N, A, n, x):\n",
    "    \n",
    "    '''\n",
    "    Probability Mass Function for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param x: number of desired items in our draw of n items\n",
    "    :returns: PMF computed at x\n",
    "    '''\n",
    "    Achoosex = comb(A,x)\n",
    "    NAchoosenx = comb(N-A, n-x)\n",
    "    Nchoosen = comb(N,n)\n",
    "    \n",
    "    return (Achoosex)*NAchoosenx/Nchoosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ab79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypergeom_cdf(N, A, n, t, max_value=None):\n",
    "    \n",
    "    '''\n",
    "    Cumulative Density Funtion for Hypergeometric Distribution\n",
    "    :param N: population size\n",
    "    :param A: total number of desired items in N\n",
    "    :param n: number of draws made from N\n",
    "    :param t: number of desired items in our draw of n items up to t\n",
    "    :returns: CDF computed up to t\n",
    "    '''\n",
    "    if max_value:\n",
    "        return np.sum([hypergeom_pmf(N, A, n, x) for x in range(max_value, t+1)])\n",
    "    \n",
    "    return np.sum([hypergeom_pmf(N, A, n, x) for x in range(t+1)])\n",
    "\n",
    "hypergeom_cdf(N,A,n,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df213060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the P_NDE for a specific sub-path and sample\n",
    "def sample_P_NDE(path,z_score,threshold,N,A,n):\n",
    "    t=0\n",
    "    for node in path:\n",
    "        for gene in node:\n",
    "            if(not gene in z_score.index):\n",
    "                gene='noProbe'\n",
    "            if(z_score[gene]>=threshold):\n",
    "                t+=1\n",
    "    return hypergeom_cdf(N,A,n,t)\n",
    "\n",
    "# Calculate the P_NDE for a specific sub-path and each sample\n",
    "def P_NDE(path,z_score,threshold,N,A,n):\n",
    "    p_nde=[]\n",
    "    for sample in range(z_score.shape[0]):\n",
    "        p_nde.append(sample_P_NDE(path,z_score.iloc[sample],threshold,N,A,n))\n",
    "    return p_nde\n",
    "\n",
    "p_nde=P_NDE(node_genes[path_no],z_score_df,z_threshold,N,A,n)\n",
    "p_nde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852efec",
   "metadata": {},
   "source": [
    "### 2.8.2. P_PERT\n",
    "Calculated based on the amount of perturbation measured in each pathway.\n",
    "#### 2.8.2.1. Gene perturbation factor (PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd06f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signed normalized measured expression change of the genes\n",
    "norm_gse2034_df # Already compute 2.7.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sign of β reflects the type of interaction: +1 for induction (activation), −1 for repression and inhibition.\n",
    "def get_b(edges):\n",
    "    b=[]\n",
    "    for e in edges:\n",
    "        if(relations_dict['Activation']==e):\n",
    "            b.append(1)\n",
    "        else:\n",
    "            b.append(-1)\n",
    "    return b\n",
    "\n",
    "# Calculate the perturbation factor for each node of a specific sub-path and sample\n",
    "def sample_pf(path,edges,de,b):\n",
    "    pf=[]\n",
    "    \n",
    "    cur_node=[]\n",
    "    \n",
    "    # Calculate the perturbation factor for the first node which has zero upstream nodes\n",
    "    for gene in path[0]:\n",
    "        if(not gene in de.index):\n",
    "            gene='noProbe'\n",
    "        cur_node.append(de[gene])\n",
    "    pf.append(statistics.mean(cur_node))\n",
    "    \n",
    "    # Calculate the perturbation factor for the remaining nodes\n",
    "    for i in range(1,len(path)):\n",
    "        prev_pf=0\n",
    "        for j in range(i):\n",
    "            # The number of downstream genes of each such gene N_ds(g_j)\n",
    "            N_ds=len(path)-j-1\n",
    "            \n",
    "            prev_pf+=b[j]*(pf[j]/N_ds)\n",
    "            \n",
    "        cur_node=[]\n",
    "        for gene in path[i]:\n",
    "            if(not gene in de.index):\n",
    "                gene='noProbe'\n",
    "            cur_node.append(de[gene])\n",
    "\n",
    "        pf.append(statistics.mean(cur_node)+prev_pf)\n",
    "            \n",
    "    return pf\n",
    "\n",
    "# Calculate the perturbation factor for each node of a specific sub-path and each sample\n",
    "def PF(path,edges,de,b):\n",
    "    pf=[]\n",
    "    for sample in range(de.shape[0]):\n",
    "        pf.append(sample_pf(path,edges,de.iloc[sample],b))\n",
    "    return pf\n",
    "\n",
    "path=list(selected_df.iloc[path_no][~selected_df.iloc[path_no].isnull()])\n",
    "edges=list(path[1::2]) # Edges are at the odd columns\n",
    "b=get_b(edges)\n",
    "pf=PF(node_genes[path_no],edges,norm_gse2034_df,b)\n",
    "pf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1b93d",
   "metadata": {},
   "source": [
    "#### 2.8.2.2. Net perturbation accumulation at the level of each gene, Acc_g\n",
    "This subtraction is needed to ensure that DE genes not connected with any other genes will not contribute to the second type of evidence since such genes are already taken into consideration in the ORA and captured by P_NDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_accumulation(path,pf,de):\n",
    "    acc=[]\n",
    "    for node in range(len(pf)):\n",
    "        cur_de=[]\n",
    "        for gene in path[node]:\n",
    "            if(not gene in de.index):\n",
    "                gene='noProbe'\n",
    "            cur_de.append(de[gene])\n",
    "        acc.append(pf[node]-statistics.mean(cur_de))\n",
    "    return acc\n",
    "\n",
    "def Accumulation(path,pf,de):\n",
    "    acc=[]\n",
    "    for sample in range(de.shape[0]):\n",
    "        acc.append(sample_accumulation(path,pf[sample],de.iloc[sample]))\n",
    "    return acc\n",
    "\n",
    "acc=Accumulation(node_genes[path_no],pf,norm_gse2034_df)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83f5a9",
   "metadata": {},
   "source": [
    "#### 2.8.2.3. Total net accumulated perturbation in the pathway, t_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_A(acc):\n",
    "    t_a=[]\n",
    "    for sample in acc:\n",
    "        t_a.append(sum(sample))\n",
    "    return t_a\n",
    "\n",
    "t_a=t_A(acc)\n",
    "t_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefeaf4",
   "metadata": {},
   "source": [
    "#### 2.8.2.4. Bootstrap procedure for computing a p-value from pathway perturbations\n",
    "The probability to observe a total accumulated perturbation of the pathway, T_A, more extreme than t_A just by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b064129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Identity function I(x): returns 1 if x is true and 0 otherwise \n",
    "def I(T_A_c,t_A_c):\n",
    "    if(t_A_c>=0):\n",
    "        if(T_A_c>=t_A_c):\n",
    "            return 1\n",
    "    else:\n",
    "        if(T_A_c<=t_A_c):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def iteration_Acc(path,edges,expression,z_score,threshold,b,all_de_genes,T_A=[],N=2000):\n",
    "    if(N==0):\n",
    "        return T_A\n",
    "    \n",
    "    new_path=path.copy()\n",
    "    \n",
    "    N_de=0\n",
    "    pos_de={} # Dictionary : {gene: position}\n",
    "    for node in range(len(new_path)):\n",
    "        for gene in range(len(new_path[node])):\n",
    "            if(z_score[new_path[node][gene]]>threshold):\n",
    "                N_de+=1\n",
    "                pos_de.update({new_path[node][gene]:[node,gene]})\n",
    "    \n",
    "    new_de_pos=[]\n",
    "    for gene in pos_de:\n",
    "        tmp_de_pos=random.randint(0,len(all_de_genes)-1)\n",
    "        while tmp_de_pos in new_de_pos:\n",
    "            tmp_de_pos=random.randint(0,len(all_de_genes)-1)\n",
    "        new_de_pos.append(tmp_de_pos)\n",
    "        new_path[pos_de[gene][0]][pos_de[gene][1]]=all_de_genes[tmp_de_pos] # Replace gene with random from DE list\n",
    "    \n",
    "    # Compute the perturbation accumulations, Acc, for each gene/node in subpath\n",
    "    pf=sample_pf(new_path,edges,expression,b)\n",
    "    acc=sample_accumulation(new_path,pf,expression)\n",
    "    \n",
    "    # The net total accumulation is computed as the sum of all perturbation accumulations across each pathway (T_A(k))\n",
    "    T_A.append(sum(acc))\n",
    "    \n",
    "    return iteration_Acc(path,edges,expression,z_score,threshold,b,all_de_genes,T_A,N-1)\n",
    "                \n",
    "\n",
    "# From supplementary materials\n",
    "def sample_P_PERT(path,edges,expression,z_score,threshold,b,N=2000):\n",
    "    # The data for the observed subpath\n",
    "    observed_pf=sample_pf(path,edges,expression,b)\n",
    "    observed_acc=sample_accumulation(path,observed_pf,expression)\n",
    "    observed_T_A=sum(observed_acc)\n",
    "    \n",
    "    all_de_genes=z_score[z_score>z_threshold].index\n",
    "    \n",
    "    # The net total accumulation is computed as the sum of all perturbation accumulations across each pathway (T_A(k))\n",
    "    T_A=iteration_Acc(path,edges,expression,z_score,threshold,b,all_de_genes)\n",
    "    \n",
    "    # Compute the median of T_A and subtract it from T_A(k) values centering their distribution around 0\n",
    "    T_A_median=statistics.median(T_A)\n",
    "    T_A_c=[t-T_A_median for t in T_A] # Corrected values (T_A_c(k))\n",
    "    \n",
    "    # The observed net total accumulation (T_A) is also corrected for the shift in the null distribution median to give, t_A_c\n",
    "    t_A_c=[]\n",
    "    for t in range(len(T_A)):\n",
    "        t_A_c.append(T_A[t]-T_A_c[t]) # Subtract from the observed net total accumulation (T_A) the corresponding corrected values (T_A_c)\n",
    "    \n",
    "    t_A_c=observed_T_A-statistics.median(t_A_c)\n",
    "    \n",
    "    # If t_A_c is positive the pathway is activated (or positively perturbed). If t_A_c is negative then the pathway is\n",
    "    # inhibited (or negatively perturbed) --> indentity function\n",
    "    identity_sum=0\n",
    "    for k in range(N):\n",
    "        identity_sum+=I(T_A_c[k],t_A_c)\n",
    "    \n",
    "    # The probability to observe such total net inhibition or activation just by chance (P_PERT)\n",
    "    p_pert=identity_sum/N\n",
    "    \n",
    "    return p_pert\n",
    "\n",
    "def P_PERT(path,edges,expression,z_score,threshold,b):\n",
    "    p_pert=[]\n",
    "    for sample in range(expression.shape[0]):\n",
    "        print(sample*100/expression.shape[0])\n",
    "        p_pert.append(sample_P_PERT(path,edges,expression.iloc[sample],z_score.iloc[sample],z_threshold,b))\n",
    "    return p_pert\n",
    "    \n",
    "p_pert=P_PERT(node_genes[path_no],edges,norm_gse2034_df,z_score_df,z_threshold,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec54cb",
   "metadata": {},
   "source": [
    "### 2.8.3. Create one DataFrame, and calculate the value of c, which is necessary for the computation of P_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c35e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spia_data_df=pd.DataFrame([p_nde,p_pert]).T\n",
    "spia_data_df.columns=['P_NDE','P_PERT']\n",
    "spia_data_df['c']=spia_data_df['P_NDE']*spia_data_df['P_PERT']\n",
    "spia_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7741e6b",
   "metadata": {},
   "source": [
    "### 2.8.4. Global probability value, P_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5805215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_P_G(c):\n",
    "    return c-c*np.log(c+1)\n",
    "\n",
    "def P_G(samples):\n",
    "    p_g=[]\n",
    "    for sample in range(samples.shape[0]):\n",
    "        p_g.append(sample_P_G(samples.iloc[sample]))\n",
    "    return p_g\n",
    "\n",
    "#spia_p_g=get_p_g(spia_data_df)\n",
    "#spia_p_g\n",
    "p_g=P_G(spia_data_df['c'])\n",
    "p_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933763d0",
   "metadata": {},
   "source": [
    "### 2.8.5. Create DataFrame DataFrame with final score of each sub-path for a specific sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spia_df=pd.DataFrame(p_g,columns=[path_no])\n",
    "#spia_df.to_csv('Results/SPIA.csv',index=False) # Already somputed\n",
    "spia_df = pd.read_csv ('Results/SPIA.csv')\n",
    "spia_df.index=gse2034_df.index\n",
    "spia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe3a9a",
   "metadata": {},
   "source": [
    "## 2.9. SubSPIA\n",
    "### 2.9.1. The statistical significance of subpathways (P_NDE)\n",
    "Two types of evidence: the overrepresentation of DEGs and the abnormal perturbation in a given subpathway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a1465",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cbd06",
   "metadata": {},
   "source": [
    "## 3.2.  Machine Learning\n",
    "Each Machine Learning Algorithm is applied to each tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c94f27",
   "metadata": {},
   "source": [
    "Split data in training and testing sets (size reduction)\n",
    "- Training set size: 70%\n",
    "- Testing set size: remaining 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202923c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tools_scores={'MinePath':minepath_df,'TAPPA':tappa_df}\n",
    "\n",
    "training_data={}\n",
    "testing_data={}\n",
    "training_labels={}\n",
    "testing_labels={}\n",
    "\n",
    "for tool in tools_scores:\n",
    "    tmp_training_data, tmp_testing_data, tmp_training_labels, tmp_testing_labels = train_test_split(tools_scores[tool], tools_scores[tool].index, test_size = 0.3 ,random_state = 0)\n",
    "    training_data.update({tool:tmp_training_data})\n",
    "    testing_data.update({tool:tmp_testing_data})\n",
    "    training_labels.update({tool:tmp_training_labels})\n",
    "    testing_labels.update({tool:tmp_testing_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080c7ee",
   "metadata": {},
   "source": [
    "### 3.2.1. K-nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13374a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "knn_score={}\n",
    "\n",
    "for tool in tools_scores:\n",
    "    error = []\n",
    "\n",
    "    # Calculating error for K values between 1 and 40\n",
    "    for i in range(1, 40):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(training_data[tool], training_labels[tool])\n",
    "        pred_i = knn.predict(testing_data[tool])\n",
    "        error.append(np.mean(pred_i != testing_labels[tool]))\n",
    "\n",
    "    # k equals the number of neighbors that have the lowest errors\n",
    "    k=error.index(min(error))+1\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(training_data[tool], training_labels[tool])\n",
    "    predictions=knn.predict(testing_data[tool])\n",
    "    knn_score.update({tool:knn.score(testing_data[tool], testing_labels[tool])})\n",
    "    \n",
    "knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c70dbc",
   "metadata": {},
   "source": [
    "### 3.2.2. Decision Trees\n",
    "- Tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "- Graphical representation for getting all the possible solutions to a problem/decision based on given conditions.\n",
    "- A decision tree simply asks a question, and based on the answer (Yes/No), it further split the tree into subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "decision_tree_score={}\n",
    "\n",
    "for tool in tools_scores:\n",
    "    # Create Decision Tree classifer object\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    dt_clf = dt_clf.fit(training_data[tool],training_labels[tool])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = dt_clf.predict(testing_data[tool])\n",
    "    \n",
    "    decision_tree_score.update({tool:metrics.accuracy_score(testing_labels[tool], y_pred)})\n",
    "    \n",
    "decision_tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d698d",
   "metadata": {},
   "source": [
    "### 3.2.3. Logistic Regression\n",
    "- Binary classification problems (problems with two class values)\n",
    "- Function used at the core of the method: the logistic function (a.k.a. sigmoid function)\n",
    "    - It's an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1, but never exactly at those limits \n",
    "    - 1 / (1 + e^-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f761b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_score={}\n",
    "\n",
    "for tool in tools_scores:\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(training_data[tool], training_labels[tool])\n",
    "\n",
    "    y_pred = logreg.predict(testing_data[tool])\n",
    "    logreg_score.update({tool:logreg.score(testing_data[tool], testing_labels[tool])})\n",
    "\n",
    "logreg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b0243",
   "metadata": {},
   "source": [
    "### 3.2.4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301562bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "svm_score={}\n",
    "\n",
    "for tool in tools_scores:\n",
    "    #Create a svm Classifier\n",
    "    svm_clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    svm_clf.fit(training_data[tool], training_labels[tool])\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = svm_clf.predict(testing_data[tool])\n",
    "    \n",
    "    svm_score.update({tool:metrics.accuracy_score(testing_labels[tool], y_pred)})\n",
    "    \n",
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecc4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
